{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Cross-Encoder Reranking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 â€” Check GPU + Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "import torch\n",
    "print(f'CUDA available : {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU            : {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    print('âš ï¸  No GPU found. Go to Runtime â†’ Change runtime type â†’ T4 GPU')\n",
    "\n",
    "!pip install sentence-transformers faiss-gpu pandas numpy tqdm -q\n",
    "print('âœ… Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 â€” Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DATA_DIR = Path('/content/drive/MyDrive/ShopSense/data')\n",
    "\n",
    "# Verify all required files are present\n",
    "required = ['products_clean.csv', 'faiss_index.bin', 'faiss_metadata.json']\n",
    "print('Checking required files...')\n",
    "for fname in required:\n",
    "    fpath = DATA_DIR / fname\n",
    "    if fpath.exists():\n",
    "        print(f'  âœ… {fname} ({fpath.stat().st_size/1024:.0f} KB)')\n",
    "    else:\n",
    "        print(f'  âŒ {fname} NOT FOUND â€” upload it to Drive first!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 â€” Load FAISS Index + Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(str(DATA_DIR / 'faiss_index.bin'))\n",
    "print(f'âœ… FAISS index loaded â€” {index.ntotal:,} vectors')\n",
    "\n",
    "# Load metadata\n",
    "with open(DATA_DIR / 'faiss_metadata.json') as f:\n",
    "    metadata = json.load(f)\n",
    "print(f'âœ… Metadata loaded   â€” {len(metadata):,} products')\n",
    "\n",
    "# Load products dataframe (used for price filtering later)\n",
    "df = pd.read_csv(DATA_DIR / 'products_clean.csv')\n",
    "\n",
    "# Clean up NaN prices â€” fill with median price\n",
    "median_price = df['price'].median()\n",
    "df['price'] = df['price'].fillna(median_price)\n",
    "\n",
    "# Also update metadata prices to match\n",
    "price_map = df.set_index('asin')['price'].to_dict()\n",
    "for item in metadata:\n",
    "    if item.get('price') is None or str(item.get('price')) == 'nan':\n",
    "        item['price'] = price_map.get(item['asin'], median_price)\n",
    "\n",
    "print(f'âœ… Products loaded   â€” {len(df):,} rows')\n",
    "print(f'   Median price used for NaN fill: ${median_price:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 â€” Load Bi-Encoder (same model as Phase 2)\n",
    "This embeds the query into a vector for FAISS search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print('Loading bi-encoder (same as Phase 2)...')\n",
    "bi_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "bi_encoder.max_seq_length = 256\n",
    "\n",
    "print(f'âœ… Bi-encoder loaded')\n",
    "print(f'   Model : all-MiniLM-L6-v2')\n",
    "print(f'   Dim   : {bi_encoder.get_sentence_embedding_dimension()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 â€” Load Cross-Encoder Reranker\n",
    "`cross-encoder/ms-marco-MiniLM-L-6-v2` is trained on MS MARCO â€” a massive dataset of real search queries and passage relevance judgements. It scores (query, product) pairs directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "print('Loading cross-encoder reranker...')\n",
    "cross_encoder = CrossEncoder(\n",
    "    'cross-encoder/ms-marco-MiniLM-L-6-v2',\n",
    "    max_length=512,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "print(f'âœ… Cross-encoder loaded')\n",
    "print(f'   Model  : cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "print(f'   Device : {\"GPU (cuda)\" if torch.cuda.is_available() else \"CPU\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 â€” Build the Full Retrieve + Rerank Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def retrieve_and_rerank(\n",
    "    query: str,\n",
    "    top_k_retrieve: int = 20,   # FAISS retrieves this many\n",
    "    top_k_final: int = 5,       # reranker picks this many\n",
    "    min_price: float = None,    # optional price filter\n",
    "    max_price: float = None,    # optional price filter\n",
    "    min_rating: float = None    # optional rating filter\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Full pipeline: FAISS retrieval â†’ optional filtering â†’ cross-encoder reranking.\n",
    "\n",
    "    Returns dict with results + timing info.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "\n",
    "    # â”€â”€ Stage 1: FAISS Retrieval â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    query_embedding = bi_encoder.encode(\n",
    "        [query],\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=True\n",
    "    ).astype('float32')\n",
    "\n",
    "    scores, indices = index.search(query_embedding, top_k_retrieve)\n",
    "\n",
    "    candidates = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        product = metadata[idx].copy()\n",
    "        product['faiss_score'] = round(float(score), 4)\n",
    "        candidates.append(product)\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    # â”€â”€ Stage 2: Optional Filters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    filtered = candidates\n",
    "    if min_price is not None:\n",
    "        filtered = [p for p in filtered if p.get('price') and p['price'] >= min_price]\n",
    "    if max_price is not None:\n",
    "        filtered = [p for p in filtered if p.get('price') and p['price'] <= max_price]\n",
    "    if min_rating is not None:\n",
    "        filtered = [p for p in filtered if p.get('rating') and p['rating'] >= min_rating]\n",
    "\n",
    "    # If filters removed too many, fall back to unfiltered\n",
    "    if len(filtered) < 3:\n",
    "        print(f'  âš ï¸  Only {len(filtered)} candidates after filtering â€” relaxing filters')\n",
    "        filtered = candidates\n",
    "\n",
    "    t2 = time.time()\n",
    "\n",
    "    # â”€â”€ Stage 3: Cross-Encoder Reranking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Build (query, product_text) pairs for the cross-encoder\n",
    "    pairs = [\n",
    "        (query, f\"{p['title']}. {str(p.get('description', ''))[:200]}\")\n",
    "        for p in filtered\n",
    "    ]\n",
    "\n",
    "    rerank_scores = cross_encoder.predict(pairs)\n",
    "\n",
    "    # Attach rerank scores and sort\n",
    "    for product, score in zip(filtered, rerank_scores):\n",
    "        product['rerank_score'] = round(float(score), 4)\n",
    "\n",
    "    reranked = sorted(filtered, key=lambda x: x['rerank_score'], reverse=True)\n",
    "    final = reranked[:top_k_final]\n",
    "\n",
    "    t3 = time.time()\n",
    "\n",
    "    return {\n",
    "        'query'        : query,\n",
    "        'results'      : final,\n",
    "        'timing': {\n",
    "            'faiss_ms'  : round((t1 - t0) * 1000, 1),\n",
    "            'filter_ms' : round((t2 - t1) * 1000, 1),\n",
    "            'rerank_ms' : round((t3 - t2) * 1000, 1),\n",
    "            'total_ms'  : round((t3 - t0) * 1000, 1)\n",
    "        },\n",
    "        'counts': {\n",
    "            'retrieved' : len(candidates),\n",
    "            'after_filter': len(filtered),\n",
    "            'final'     : len(final)\n",
    "        }\n",
    "    }\n",
    "\n",
    "print('âœ… retrieve_and_rerank() pipeline ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 â€” Display Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_reranked(result: dict, show_scores: bool = True):\n",
    "    \"\"\"Pretty print reranked results with before/after score comparison.\"\"\"\n",
    "    print(f'ðŸ” Query : \"{result[\"query\"]}\"')\n",
    "    print(f'â±ï¸  Timing: FAISS {result[\"timing\"][\"faiss_ms\"]}ms '\n",
    "          f'| Rerank {result[\"timing\"][\"rerank_ms\"]}ms '\n",
    "          f'| Total {result[\"timing\"][\"total_ms\"]}ms')\n",
    "    print(f'ðŸ“¦ Retrieved {result[\"counts\"][\"retrieved\"]} â†’ '\n",
    "          f'Filtered to {result[\"counts\"][\"after_filter\"]} â†’ '\n",
    "          f'Final {result[\"counts\"][\"final\"]}')\n",
    "    print('â”€' * 68)\n",
    "    for i, r in enumerate(result['results'], 1):\n",
    "        price_str = f\"${r['price']:.2f}\" if r.get('price') else 'N/A'\n",
    "        print(f\"{i}. {r['title'][:70]}\")\n",
    "        print(f\"   Price: {price_str}  |  Rating: {r.get('rating', 'N/A')}â­ \"\n",
    "              f\"({int(r.get('rating_count', 0)):,} reviews)\")\n",
    "        if show_scores:\n",
    "            print(f\"   FAISS score: {r['faiss_score']}  â†’  Rerank score: {r['rerank_score']}\")\n",
    "        print()\n",
    "    print('=' * 68)\n",
    "\n",
    "print('âœ… Display helper ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 â€” Test the Pipeline\n",
    "Same queries as Phase 2 so you can directly compare before/after reranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1 â€” Phase 2 returned a coffee TABLE as top result. Let's see if reranker fixes it.\n",
    "result1 = retrieve_and_rerank('compact coffee maker for small kitchen')\n",
    "display_reranked(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2 â€” with price filter this time\n",
    "result2 = retrieve_and_rerank('non stick frying pan', max_price=30.0)\n",
    "display_reranked(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3 â€” gift query\n",
    "result3 = retrieve_and_rerank('gift for someone who loves cooking')\n",
    "display_reranked(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 4 â€” storage with rating filter\n",
    "result4 = retrieve_and_rerank('storage solution for small apartment', min_rating=4.3)\n",
    "display_reranked(result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 5 â€” try your own!\n",
    "result5 = retrieve_and_rerank('durable water bottle for gym')\n",
    "display_reranked(result5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 â€” Before vs After Reranking Comparison\n",
    "Shows exactly how reranking changed the order from raw FAISS results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_before_after(query: str, top_k_retrieve: int = 20, top_k_final: int = 5):\n",
    "    \"\"\"Side by side comparison of FAISS-only vs reranked results.\"\"\"\n",
    "\n",
    "    # Get FAISS only results\n",
    "    query_embedding = bi_encoder.encode(\n",
    "        [query], normalize_embeddings=True, convert_to_numpy=True\n",
    "    ).astype('float32')\n",
    "    scores, indices = index.search(query_embedding, top_k_retrieve)\n",
    "\n",
    "    faiss_results = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        if idx != -1:\n",
    "            p = metadata[idx].copy()\n",
    "            p['faiss_score'] = round(float(score), 4)\n",
    "            faiss_results.append(p)\n",
    "\n",
    "    # Get reranked results\n",
    "    reranked = retrieve_and_rerank(query, top_k_retrieve, top_k_final)\n",
    "\n",
    "    print(f'ðŸ” Query: \"{query}\"')\n",
    "    print(f'{\"FAISS Only (top 5)\":<45} {\"After Reranking (top 5)\"}')\n",
    "    print('â”€' * 100)\n",
    "    for i in range(top_k_final):\n",
    "        left  = faiss_results[i]['title'][:42] if i < len(faiss_results) else ''\n",
    "        right = reranked['results'][i]['title'][:42] if i < len(reranked['results']) else ''\n",
    "        changed = 'ðŸ”„' if left != right else '  '\n",
    "        print(f\"{i+1}. {left:<45} {changed}  {i+1}. {right}\")\n",
    "    print()\n",
    "\n",
    "# Run comparison on the coffee query where Phase 2 had the wrong top result\n",
    "compare_before_after('compact coffee maker for small kitchen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_before_after('gift for someone who loves cooking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 â€” Save Pipeline Results to Drive\n",
    "Saves sample query results as JSON â€” useful for Phase 7 evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = [\n",
    "    'compact coffee maker for small kitchen',\n",
    "    'non stick frying pan',\n",
    "    'gift for someone who loves cooking',\n",
    "    'storage solution for small apartment',\n",
    "    'durable water bottle for gym',\n",
    "    'budget friendly knife set for beginner cook',\n",
    "    'air fryer for family of four',\n",
    "    'cute kitchen decor for modern home'\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "print('Running all sample queries...')\n",
    "for q in sample_queries:\n",
    "    r = retrieve_and_rerank(q)\n",
    "    all_results.append(r)\n",
    "    print(f'  âœ… \"{q}\"')\n",
    "\n",
    "# Save to Drive\n",
    "results_path = DATA_DIR / 'sample_reranked_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(all_results, f, indent=2)\n",
    "\n",
    "print(f'\\nâœ… Saved {len(all_results)} query results â†’ {results_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 â€” Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show average timing across all sample queries\n",
    "avg_faiss  = sum(r['timing']['faiss_ms']  for r in all_results) / len(all_results)\n",
    "avg_rerank = sum(r['timing']['rerank_ms'] for r in all_results) / len(all_results)\n",
    "avg_total  = sum(r['timing']['total_ms']  for r in all_results) / len(all_results)\n",
    "\n",
    "print('=' * 55)\n",
    "print('     PHASE 3 COMPLETE â€” SUMMARY')\n",
    "print('=' * 55)\n",
    "print(f'  Bi-encoder    : all-MiniLM-L6-v2')\n",
    "print(f'  Cross-encoder : cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "print(f'  Pipeline      : FAISS top-20 â†’ rerank â†’ top-5')\n",
    "print()\n",
    "print(f'  Average Latency across {len(all_results)} queries:')\n",
    "print(f'    FAISS retrieval : {avg_faiss:.1f} ms')\n",
    "print(f'    Reranking       : {avg_rerank:.1f} ms')\n",
    "print(f'    Total           : {avg_total:.1f} ms')\n",
    "print()\n",
    "print('  Files saved to Drive:')\n",
    "print('    âœ… data/sample_reranked_results.json')\n",
    "print()\n",
    "print('  âž¡ï¸  Next: Phase 4 â€” RAG Review Summarization (VS Code)')\n",
    "print('=' * 55)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
