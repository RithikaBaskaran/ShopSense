{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: RAG Review Summarization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 â€” Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "âœ… Dependencies installed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install groq sentence-transformers faiss-cpu pandas numpy python-dotenv tqdm -q\n",
    "print('âœ… Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 â€” Set Up Groq API Key\n",
    "We store the key in a `.env` file so it never gets accidentally pushed to GitHub.\n",
    "Your `.gitignore` from Phase 1 already excludes `.env` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… .env file already exists â€” skipping\n",
      "âœ… Groq API key loaded: gsk_h33q...k0jq\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "env_path = Path('.env')\n",
    "\n",
    "# Only create if it doesn't exist yet\n",
    "if not env_path.exists():\n",
    "    # Paste your Groq API key below between the quotes\n",
    "    groq_key = 'YOUR_GROQ_API_KEY_HERE'\n",
    "    env_path.write_text(f'GROQ_API_KEY={groq_key}\\n')\n",
    "    print(f'âœ… .env file created')\n",
    "else:\n",
    "    print(f'âœ… .env file already exists â€” skipping')\n",
    "\n",
    "# Load the key into environment\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('GROQ_API_KEY')\n",
    "if api_key and api_key != 'YOUR_GROQ_API_KEY_HERE':\n",
    "    print(f'âœ… Groq API key loaded: {api_key[:8]}...{api_key[-4:]}')\n",
    "else:\n",
    "    print('âŒ Key not set â€” edit .env and replace YOUR_GROQ_API_KEY_HERE with your actual key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 â€” Test Groq Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… It seems like you're referring to the Groq company, a semiconductor company known for its AI processors\n",
      "   Model : llama3-8b-8192\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "groq_client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "\n",
    "# Quick test call\n",
    "test_response = groq_client.chat.completions.create(\n",
    "    model='llama-3.1-8b-instant',\n",
    "    messages=[{'role': 'user', 'content': 'Say: Groq connection successful!'}],\n",
    "    max_tokens=20\n",
    ")\n",
    "\n",
    "print(f'âœ… {test_response.choices[0].message.content}')\n",
    "print(f'   Model : llama3-8b-8192')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 â€” Load Reviews from Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 5,566 reviews\n",
      "   Products covered : 2,003\n",
      "   Avg review length: 268 chars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B078NWLG1P</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Bought this for entertaining &amp; it's a fun piec...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B082P23BMP</td>\n",
       "      <td>Great sheets</td>\n",
       "      <td>I have these sheets in two colors. They are gr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00XM0M1QQ</td>\n",
       "      <td>Love mine, have had over a year</td>\n",
       "      <td>Love mine, have had over a year. Does not stor...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                     review_title  \\\n",
       "0  B078NWLG1P                       Five Stars   \n",
       "1  B082P23BMP                     Great sheets   \n",
       "2  B00XM0M1QQ  Love mine, have had over a year   \n",
       "\n",
       "                                         review_text  rating  helpful_vote  \\\n",
       "0  Bought this for entertaining & it's a fun piec...     5.0             0   \n",
       "1  I have these sheets in two colors. They are gr...     5.0             0   \n",
       "2  Love mine, have had over a year. Does not stor...     5.0             0   \n",
       "\n",
       "   verified_purchase  \n",
       "0               True  \n",
       "1               True  \n",
       "2              False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "\n",
    "df_reviews = pd.read_csv(DATA_DIR / 'reviews_clean.csv')\n",
    "df_reviews = df_reviews.dropna(subset=['review_text']).reset_index(drop=True)\n",
    "\n",
    "print(f'âœ… Loaded {len(df_reviews):,} reviews')\n",
    "print(f'   Products covered : {df_reviews[\"asin\"].nunique():,}')\n",
    "print(f'   Avg review length: {df_reviews[\"review_text\"].str.len().mean():.0f} chars')\n",
    "df_reviews.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 â€” Chunk Reviews\n",
    "Long reviews get split into smaller chunks so the retriever can pinpoint\n",
    "the most relevant part of a review rather than the whole thing.\n",
    "Short reviews are kept as-is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews loaded: 5,566\n",
      "Sample review text: Bought this for entertaining & it's a fun piece. It's smaller than I expected though.\n",
      "\n",
      "âœ… Created 5,566 review chunks\n",
      "Sample chunk: \"Bought this for entertaining & it's a fun piece. It's smaller than I expected though.\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "\n",
    "# Reload reviews fresh after kernel restart\n",
    "df_reviews = pd.read_csv(DATA_DIR / 'reviews_clean.csv')\n",
    "df_reviews = df_reviews.dropna(subset=['review_text']).reset_index(drop=True)\n",
    "print(f'Reviews loaded: {len(df_reviews):,}')\n",
    "print(f'Sample review text: {df_reviews[\"review_text\"].iloc[0][:100]}')\n",
    "\n",
    "# Simple chunking â€” no fancy logic, just split long reviews\n",
    "review_chunks = []\n",
    "\n",
    "for _, row in df_reviews.iterrows():\n",
    "    text = str(row['review_text']).strip()\n",
    "    if len(text) < 20:\n",
    "        continue\n",
    "\n",
    "    # Just take the first 250 chars â€” one chunk per review, keep it simple\n",
    "    review_chunks.append({\n",
    "        'asin'             : str(row['asin']),\n",
    "        'chunk_text'       : text[:250],\n",
    "        'review_title'     : str(row.get('review_title', '')),\n",
    "        'rating'           : float(row.get('rating', 0)),\n",
    "        'verified_purchase': bool(row.get('verified_purchase', False))\n",
    "    })\n",
    "\n",
    "print(f'\\nâœ… Created {len(review_chunks):,} review chunks')\n",
    "print(f'Sample chunk: \"{review_chunks[0][\"chunk_text\"]}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks        : 5,566\n",
      "Total reviews       : 5,566\n",
      "Estimated memory    : ~8.2 MB for embeddings alone\n",
      "Available RAM       : 9608 MB\n",
      "Total RAM           : 24576 MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(f'Total chunks        : {len(review_chunks):,}')\n",
    "print(f'Total reviews       : {len(df_reviews):,}')\n",
    "print(f'Estimated memory    : ~{len(review_chunks) * 384 * 4 / 1024 / 1024:.1f} MB for embeddings alone')\n",
    "\n",
    "# Check available memory\n",
    "import psutil\n",
    "ram = psutil.virtual_memory()\n",
    "print(f'Available RAM       : {ram.available / 1024 / 1024:.0f} MB')\n",
    "print(f'Total RAM           : {ram.total / 1024 / 1024:.0f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 â€” Embed Review Chunks + Build Review FAISS Index\n",
    "Same model as Phase 2 â€” keeps embedding space consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 2095.45it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded\n",
      "Embedding 3,008 chunks...\n",
      "âœ… Done in 5.7s â€” 3,008 vectors indexed\n",
      "âœ… Index saved â†’ data/reviews_faiss_index.bin\n",
      "âœ… Metadata saved â†’ data/reviews_metadata.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "import time\n",
    "\n",
    "print('Loading model...')\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print('âœ… Model loaded')\n",
    "\n",
    "# Embed directly into FAISS batch by batch\n",
    "EMBEDDING_DIM = 384\n",
    "review_index  = faiss.IndexFlatIP(EMBEDDING_DIM)\n",
    "BATCH_SIZE    = 64\n",
    "\n",
    "chunk_texts = [c['chunk_text'] for c in review_chunks]\n",
    "total       = len(chunk_texts)\n",
    "start       = time.time()\n",
    "\n",
    "print(f'Embedding {total:,} chunks...')\n",
    "\n",
    "for i in range(0, total, BATCH_SIZE):\n",
    "    batch = chunk_texts[i : i + BATCH_SIZE]\n",
    "    emb   = embed_model.encode(\n",
    "        batch,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=False\n",
    "    ).astype('float32')\n",
    "    review_index.add(emb)\n",
    "    del emb\n",
    "    gc.collect()\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f'âœ… Done in {elapsed:.1f}s â€” {review_index.ntotal:,} vectors indexed')\n",
    "\n",
    "# Save index\n",
    "review_index_path = DATA_DIR / 'reviews_faiss_index.bin'\n",
    "faiss.write_index(review_index, str(review_index_path))\n",
    "print(f'âœ… Index saved â†’ {review_index_path}')\n",
    "\n",
    "# Save metadata\n",
    "review_meta_path = DATA_DIR / 'reviews_metadata.json'\n",
    "with open(review_meta_path, 'w') as f:\n",
    "    json.dump(review_chunks, f)\n",
    "print(f'âœ… Metadata saved â†’ {review_meta_path}')\n",
    "\n",
    "del chunk_texts\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 â€” Build Review Retrieval Function\n",
    "Given a product ASIN + a query, retrieves the most relevant review chunks for that product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… get_relevant_review_chunks() ready.\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_review_chunks(\n",
    "    asin: str,\n",
    "    query: str,\n",
    "    top_k: int = 5\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Retrieve the most query-relevant review chunks for a specific product.\n",
    "\n",
    "    Args:\n",
    "        asin  : Product ASIN to filter reviews by\n",
    "        query : User query to find relevant review content\n",
    "        top_k : Number of chunks to retrieve\n",
    "\n",
    "    Returns:\n",
    "        List of relevant review chunk dicts\n",
    "    \"\"\"\n",
    "    # Get all chunk indices that belong to this product\n",
    "    product_chunk_indices = [\n",
    "        i for i, chunk in enumerate(review_chunks)\n",
    "        if chunk['asin'] == asin\n",
    "    ]\n",
    "\n",
    "    if not product_chunk_indices:\n",
    "        return []   # No reviews for this product\n",
    "\n",
    "    # Embed the query\n",
    "    query_emb = embed_model.encode(\n",
    "        [query],\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=True\n",
    "    ).astype('float32')\n",
    "\n",
    "    # Search the review index â€” fetch more than we need so we can filter by ASIN\n",
    "    fetch_k = min(len(review_chunks), top_k * 20)\n",
    "    scores, indices = review_index.search(query_emb, fetch_k)\n",
    "\n",
    "    # Filter to only chunks belonging to this product\n",
    "    product_set = set(product_chunk_indices)\n",
    "    relevant = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        if idx in product_set:\n",
    "            chunk = review_chunks[idx].copy()\n",
    "            chunk['relevance_score'] = round(float(score), 4)\n",
    "            relevant.append(chunk)\n",
    "        if len(relevant) >= top_k:\n",
    "            break\n",
    "\n",
    "    return relevant\n",
    "\n",
    "\n",
    "print('âœ… get_relevant_review_chunks() ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 â€” Build the RAG Summarization Function\n",
    "Retrieves relevant review chunks for a product then passes them to Llama 3 via Groq to generate a structured pros/cons summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… summarize_product_reviews() ready.\n"
     ]
    }
   ],
   "source": [
    "NO_REVIEW_MESSAGE = 'No reviews available for this product yet.'\n",
    "\n",
    "def summarize_product_reviews(\n",
    "    product: dict,\n",
    "    query: str,\n",
    "    top_k_chunks: int = 5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    RAG pipeline: retrieve relevant review chunks â†’ summarize with Llama 3.\n",
    "\n",
    "    Args:\n",
    "        product      : Product dict with asin, title, price, rating etc.\n",
    "        query        : Original user query\n",
    "        top_k_chunks : Number of review chunks to retrieve\n",
    "\n",
    "    Returns:\n",
    "        Dict with pros, cons, verdict, and review_count\n",
    "    \"\"\"\n",
    "    asin  = product['asin']\n",
    "    title = product['title']\n",
    "\n",
    "    # â”€â”€ Step 1: Retrieve relevant review chunks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    chunks = get_relevant_review_chunks(asin, query, top_k=top_k_chunks)\n",
    "\n",
    "    if not chunks:\n",
    "        return {\n",
    "            'pros'        : [],\n",
    "            'cons'        : [],\n",
    "            'verdict'     : NO_REVIEW_MESSAGE,\n",
    "            'review_count': 0\n",
    "        }\n",
    "\n",
    "    # â”€â”€ Step 2: Build context from chunks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    review_context = '\\n'.join([\n",
    "        f\"- [{'âœ“' if c.get('verified_purchase') else '?'} {c['rating']}â˜…] {c['chunk_text']}\"\n",
    "        for c in chunks\n",
    "    ])\n",
    "\n",
    "    # â”€â”€ Step 3: Call Groq Llama 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    prompt = f\"\"\"You are a helpful shopping assistant. A user is looking for: \"{query}\"\n",
    "\n",
    "Here are real customer review excerpts for the product \"{title}\":\n",
    "\n",
    "{review_context}\n",
    "\n",
    "Based ONLY on the reviews above, provide a concise summary. Respond in this exact JSON format:\n",
    "{{\n",
    "  \"pros\": [\"pro 1\", \"pro 2\", \"pro 3\"],\n",
    "  \"cons\": [\"con 1\", \"con 2\"],\n",
    "  \"verdict\": \"One sentence verdict on whether this product suits the user's query.\"\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Only include pros/cons that are mentioned in the reviews\n",
    "- Keep each point under 15 words\n",
    "- If reviews are mostly positive, you may have fewer cons (and vice versa)\n",
    "- Respond with valid JSON only, no extra text\"\"\"\n",
    "\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model='llama-3.1-8b-instant',\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        max_tokens=300,\n",
    "        temperature=0.3    # low temperature = more consistent structured output\n",
    "    )\n",
    "\n",
    "    raw = response.choices[0].message.content.strip()\n",
    "\n",
    "    # â”€â”€ Step 4: Parse JSON response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    try:\n",
    "        import json, re\n",
    "        # Strip markdown code fences if present\n",
    "        clean = re.sub(r'```json|```', '', raw).strip()\n",
    "        parsed = json.loads(clean)\n",
    "        parsed['review_count'] = len(chunks)\n",
    "        return parsed\n",
    "    except Exception:\n",
    "        # Fallback if JSON parsing fails\n",
    "        return {\n",
    "            'pros'        : [],\n",
    "            'cons'        : [],\n",
    "            'verdict'     : raw[:300],\n",
    "            'review_count': len(chunks)\n",
    "        }\n",
    "\n",
    "\n",
    "print('âœ… summarize_product_reviews() ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 â€” Build the Full Display Function\n",
    "Combines product info + RAG summary into one clean output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… display_product_with_summary() ready.\n"
     ]
    }
   ],
   "source": [
    "def display_product_with_summary(product: dict, query: str):\n",
    "    \"\"\"Display a product card with its RAG-generated review summary.\"\"\"\n",
    "    summary = summarize_product_reviews(product, query)\n",
    "\n",
    "    price_str = f\"${product['price']:.2f}\" if product.get('price') else 'N/A'\n",
    "\n",
    "    print(f\"{'â”€'*65}\")\n",
    "    print(f\"ğŸ“¦ {product['title'][:70]}\")\n",
    "    print(f\"   ğŸ’° {price_str}  |  â­ {product.get('rating', 'N/A')} ({int(product.get('rating_count', 0)):,} reviews)\")\n",
    "    print(f\"   ğŸ”‘ ASIN: {product['asin']}\")\n",
    "    print()\n",
    "\n",
    "    if summary['review_count'] == 0:\n",
    "        print(f\"   ğŸ“ {NO_REVIEW_MESSAGE}\")\n",
    "    else:\n",
    "        print(f\"   ğŸ“ Review Summary (from {summary['review_count']} relevant excerpts):\")\n",
    "        print()\n",
    "        if summary.get('pros'):\n",
    "            print('   âœ… Pros:')\n",
    "            for pro in summary['pros']:\n",
    "                print(f'      â€¢ {pro}')\n",
    "        if summary.get('cons'):\n",
    "            print('   âŒ Cons:')\n",
    "            for con in summary['cons']:\n",
    "                print(f'      â€¢ {con}')\n",
    "        print()\n",
    "        print(f\"   ğŸ’¬ Verdict: {summary.get('verdict', '')}\")\n",
    "    print()\n",
    "\n",
    "print('âœ… display_product_with_summary() ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 â€” Test the Full RAG Pipeline\n",
    "Load some products from Phase 1 that we know have reviews, then summarize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASINs with review chunks : 2,003\n",
      "Selected products:\n",
      "  â€¢ Coffeezone Small Candy / Nuts Decoration Ideas, Small Porcel (2 chunk(s))\n",
      "  â€¢ Touch Choice Single Serve Coffee Brewer - Silver Coffee Make (2 chunk(s))\n",
      "  â€¢ 400 Thread Count Cotton Cal King Fitted Sheets Pastel Pink 1 (2 chunk(s))\n",
      "\n",
      "ğŸ” Query: \"compact coffee maker for small kitchen\"\n",
      "Generating RAG summaries...\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ Coffeezone Small Candy / Nuts Decoration Ideas, Small Porcelain Dishes\n",
      "   ğŸ’° $8.99  |  â­ 4.3 (1,298 reviews)\n",
      "   ğŸ”‘ ASIN: B078NWLG1P\n",
      "\n",
      "   ğŸ“ No reviews available for this product yet.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ Touch Choice Single Serve Coffee Brewer - Silver Coffee Maker with Ful\n",
      "   ğŸ’° $nan  |  â­ 3.9 (89 reviews)\n",
      "   ğŸ”‘ ASIN: B00XM0M1QQ\n",
      "\n",
      "   ğŸ“ Review Summary (from 2 relevant excerpts):\n",
      "\n",
      "   âœ… Pros:\n",
      "      â€¢ Makes the best coffee\n",
      "      â€¢ Blows Keurig out of the water\n",
      "      â€¢ Love the product\n",
      "   âŒ Cons:\n",
      "      â€¢ Does not store water within\n",
      "      â€¢ Requires manual draining\n",
      "\n",
      "   ğŸ’¬ Verdict: This compact coffee maker is a great choice for small kitchens.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ 400 Thread Count Cotton Cal King Fitted Sheets Pastel Pink 1pc, 100% L\n",
      "   ğŸ’° $39.99  |  â­ 4.5 (14,104 reviews)\n",
      "   ğŸ”‘ ASIN: B082P23BMP\n",
      "\n",
      "   ğŸ“ No reviews available for this product yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load products\n",
    "df_products = pd.read_csv(DATA_DIR / 'products_clean.csv')\n",
    "\n",
    "# Find ASINs that actually have chunks in our review index\n",
    "asins_with_chunks = set(c['asin'] for c in review_chunks)\n",
    "print(f'ASINs with review chunks : {len(asins_with_chunks):,}')\n",
    "\n",
    "# Pick top 3 by number of reviews in our chunk set\n",
    "from collections import Counter\n",
    "asin_counts = Counter(c['asin'] for c in review_chunks)\n",
    "top_asins   = [asin for asin, _ in asin_counts.most_common(3)]\n",
    "\n",
    "sample_products = df_products[df_products['asin'].isin(top_asins)].to_dict(orient='records')\n",
    "\n",
    "print(f'Selected products:')\n",
    "for p in sample_products:\n",
    "    count = asin_counts[p['asin']]\n",
    "    print(f'  â€¢ {p[\"title\"][:60]} ({count} chunk(s))')\n",
    "\n",
    "# Run RAG summaries\n",
    "test_query = 'compact coffee maker for small kitchen'\n",
    "print(f'\\nğŸ” Query: \"{test_query}\"')\n",
    "print('Generating RAG summaries...\\n')\n",
    "\n",
    "for product in sample_products:\n",
    "    display_product_with_summary(product, test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 â€” Test with a Product That Has No Reviews\n",
    "Verifies graceful fallback works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing graceful fallback for product with no reviews:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ Set of 4 Irish Coffee Glass Mugs Footed 10.5 oz.Thick Wall Glass For C\n",
      "   ğŸ’° $24.95  |  â­ 4.6 (18 reviews)\n",
      "   ğŸ”‘ ASIN: B07R3DYMH6\n",
      "\n",
      "   ğŸ“ No reviews available for this product yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find a product with NO reviews\n",
    "asins_without_reviews = df_products[~df_products['asin'].isin(asins_with_reviews)]\n",
    "no_review_product = asins_without_reviews.iloc[0].to_dict()\n",
    "\n",
    "print('Testing graceful fallback for product with no reviews:')\n",
    "display_product_with_summary(no_review_product, test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11 â€” Wire RAG into the Full Retrieve + Rerank + Summarize Pipeline\n",
    "This is the complete end-to-end ShopSense pipeline so far:\n",
    "FAISS â†’ Rerank â†’ RAG Summary for each result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Product index loaded â€” 10,000 vectors\n",
      "âœ… Product metadata loaded â€” 10,000 products\n"
     ]
    }
   ],
   "source": [
    "# Load Phase 2 FAISS index + metadata for product retrieval\n",
    "product_index = faiss.read_index(str(DATA_DIR / 'faiss_index.bin'))\n",
    "with open(DATA_DIR / 'faiss_metadata.json') as f:\n",
    "    product_metadata = json.load(f)\n",
    "\n",
    "print(f'âœ… Product index loaded â€” {product_index.ntotal:,} vectors')\n",
    "print(f'âœ… Product metadata loaded â€” {len(product_metadata):,} products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… shopsense_search() pipeline ready.\n"
     ]
    }
   ],
   "source": [
    "def shopsense_search(query: str, top_k: int = 3) -> None:\n",
    "    \"\"\"\n",
    "    Full ShopSense pipeline Phases 2 + 3 + 4:\n",
    "    1. FAISS semantic retrieval (top 20)\n",
    "    2. Cross-encoder reranking (top K) â€” skipped here, using FAISS scores for now\n",
    "       (full reranker runs in Colab; Phase 5 agent will call both)\n",
    "    3. RAG review summarization for each result\n",
    "    \"\"\"\n",
    "    print(f'\\n{'='*65}')\n",
    "    print(f'ğŸ›ï¸  ShopSense Search: \"{query}\"')\n",
    "    print(f'{'='*65}\\n')\n",
    "\n",
    "    # Stage 1 â€” FAISS retrieval\n",
    "    query_emb = embed_model.encode(\n",
    "        [query],\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=True\n",
    "    ).astype('float32')\n",
    "\n",
    "    scores, indices = product_index.search(query_emb, 20)\n",
    "\n",
    "    candidates = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        product = product_metadata[idx].copy()\n",
    "        product['faiss_score'] = round(float(score), 4)\n",
    "        candidates.append(product)\n",
    "\n",
    "    top_results = candidates[:top_k]\n",
    "\n",
    "    print(f'Found {len(candidates)} candidates â†’ showing top {top_k} with review summaries:\\n')\n",
    "\n",
    "    # Stage 2 â€” RAG summarization for each result\n",
    "    for i, product in enumerate(top_results, 1):\n",
    "        print(f'Result {i} of {top_k}:')\n",
    "        display_product_with_summary(product, query)\n",
    "\n",
    "\n",
    "print('âœ… shopsense_search() pipeline ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "ğŸ›ï¸  ShopSense Search: \"non stick frying pan for everyday cooking\"\n",
      "=================================================================\n",
      "\n",
      "Found 20 candidates â†’ showing top 3 with review summaries:\n",
      "\n",
      "Result 1 of 3:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ Anyfish 8 Inch Frying Pan without Lid Nonstick Induction Skillet Small\n",
      "   ğŸ’° $nan  |  â­ 4.2 (29 reviews)\n",
      "   ğŸ”‘ ASIN: B0B12JWHF2\n",
      "\n",
      "   ğŸ“ No reviews available for this product yet.\n",
      "\n",
      "Result 2 of 3:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ MICHELANGELO Frying Pan with Lid, Nonstick 8 Inch Frying Pan with Cera\n",
      "   ğŸ’° $23.99  |  â­ 4.4 (10,637 reviews)\n",
      "   ğŸ”‘ ASIN: B0B6VTWMQW\n",
      "\n",
      "   ğŸ“ Review Summary (from 2 relevant excerpts):\n",
      "\n",
      "   âœ… Pros:\n",
      "      â€¢ Non-stick surface works well initially\n",
      "      â€¢ Easy to clean\n",
      "      â€¢ Lightweight and easy to handle\n",
      "   âŒ Cons:\n",
      "      â€¢ Non-stick surface wears off after 20 uses\n",
      "\n",
      "   ğŸ’¬ Verdict: This product is suitable for everyday cooking with some limitations.\n",
      "\n",
      "Result 3 of 3:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ Earth Pan Nonstick Cookware 12-Inch Skillet, Terra Cotta\n",
      "   ğŸ’° $nan  |  â­ 3.3 (49 reviews)\n",
      "   ğŸ”‘ ASIN: B001GTIJHA\n",
      "\n",
      "   ğŸ“ No reviews available for this product yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the full pipeline!\n",
    "shopsense_search('non stick frying pan for everyday cooking', top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "ğŸ›ï¸  ShopSense Search: \"gift for someone who loves cooking\"\n",
      "=================================================================\n",
      "\n",
      "Found 20 candidates â†’ showing top 3 with review summaries:\n",
      "\n",
      "Result 1 of 3:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ LITSTYLES Charcuterie Boards, Bamboo Cheese Board & Knife Set, Premium\n",
      "   ğŸ’° $20.99  |  â­ 3.9 (26 reviews)\n",
      "   ğŸ”‘ ASIN: B0954CX49D\n",
      "\n",
      "   ğŸ“ No reviews available for this product yet.\n",
      "\n",
      "Result 2 of 3:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ Funny Fork Gifts for Women Men Kids, Cute My Mac and Cheese Fork Engra\n",
      "   ğŸ’° $10.99  |  â­ 5.0 (11 reviews)\n",
      "   ğŸ”‘ ASIN: B097YDGMCP\n",
      "\n",
      "   ğŸ“ No reviews available for this product yet.\n",
      "\n",
      "Result 3 of 3:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“¦ Landisun Apron Kitchen Chef Cooking Gag Gift Creative Funny Grilling B\n",
      "   ğŸ’° $14.99  |  â­ 4.6 (154 reviews)\n",
      "   ğŸ”‘ ASIN: B09BVKNJYK\n",
      "\n",
      "   ğŸ“ No reviews available for this product yet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try another query\n",
    "shopsense_search('gift for someone who loves cooking', top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12 â€” Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "     PHASE 4 COMPLETE â€” SUMMARY\n",
      "=======================================================\n",
      "  Review chunks indexed : 3,008\n",
      "  Products with reviews : 2,003\n",
      "  LLM model used        : llama3-8b-8192 (Groq)\n",
      "  RAG approach          : chunk â†’ embed â†’ retrieve â†’ summarize\n",
      "\n",
      "  Files created:\n",
      "    âœ… data/reviews_faiss_index.bin (4512 KB)\n",
      "    âœ… data/reviews_metadata.json (732 KB)\n",
      "\n",
      "  Pipeline so far:\n",
      "    Phase 2 : FAISS semantic retrieval\n",
      "    Phase 3 : Cross-encoder reranking (Colab)\n",
      "    Phase 4 : RAG review summarization â† you are here\n",
      "\n",
      "  â¡ï¸  Next: Phase 5 â€” LangGraph Agent (VS Code)\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print('=' * 55)\n",
    "print('     PHASE 4 COMPLETE â€” SUMMARY')\n",
    "print('=' * 55)\n",
    "print(f'  Review chunks indexed : {review_index.ntotal:,}')\n",
    "print(f'  Products with reviews : {len(asins_with_reviews):,}')\n",
    "print(f'  LLM model used        : llama3-8b-8192 (Groq)')\n",
    "print(f'  RAG approach          : chunk â†’ embed â†’ retrieve â†’ summarize')\n",
    "print()\n",
    "print('  Files created:')\n",
    "for fname in ['reviews_faiss_index.bin', 'reviews_metadata.json']:\n",
    "    fpath = DATA_DIR / fname\n",
    "    print(f'    âœ… data/{fname} ({fpath.stat().st_size/1024:.0f} KB)')\n",
    "print()\n",
    "print('  Pipeline so far:')\n",
    "print('    Phase 2 : FAISS semantic retrieval')\n",
    "print('    Phase 3 : Cross-encoder reranking (Colab)')\n",
    "print('    Phase 4 : RAG review summarization â† you are here')\n",
    "print()\n",
    "print('  â¡ï¸  Next: Phase 5 â€” LangGraph Agent (VS Code)')\n",
    "print('=' * 55)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
