{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ›ï¸ ShopSense â€” Phase 7: Evaluation\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 â€” Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "âœ… Dependencies installed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install sentence-transformers faiss-cpu pandas numpy scikit-learn -q\n",
    "print('âœ… Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 â€” Load Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rithikabaskaran/MyFiles/ShopSense/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 2198.88it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Product index  : 10,000 vectors\n",
      "âœ… Products loaded: 10,000\n",
      "âœ… Reranked queries: 8\n",
      "\n",
      "Queries available for evaluation:\n",
      "  1. \"compact coffee maker for small kitchen\"\n",
      "  2. \"non stick frying pan\"\n",
      "  3. \"gift for someone who loves cooking\"\n",
      "  4. \"storage solution for small apartment\"\n",
      "  5. \"durable water bottle for gym\"\n",
      "  6. \"budget friendly knife set for beginner cook\"\n",
      "  7. \"air fryer for family of four\"\n",
      "  8. \"cute kitchen decor for modern home\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "\n",
    "# Load embedding model\n",
    "print('Loading model...')\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Load FAISS product index\n",
    "product_index = faiss.read_index(str(DATA_DIR / 'faiss_index.bin'))\n",
    "\n",
    "# Load product metadata\n",
    "with open(DATA_DIR / 'faiss_metadata.json') as f:\n",
    "    product_metadata = json.load(f)\n",
    "\n",
    "# Load reranked results from Phase 3 (Colab)\n",
    "with open(DATA_DIR / 'sample_reranked_results.json') as f:\n",
    "    reranked_results = json.load(f)\n",
    "\n",
    "print(f'âœ… Product index  : {product_index.ntotal:,} vectors')\n",
    "print(f'âœ… Products loaded: {len(product_metadata):,}')\n",
    "print(f'âœ… Reranked queries: {len(reranked_results)}')\n",
    "print(f'\\nQueries available for evaluation:')\n",
    "for i, r in enumerate(reranked_results, 1):\n",
    "    print(f'  {i}. \"{r[\"query\"]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 â€” Build the Test Set\n",
    "\n",
    "For evaluation we need **ground truth** â€” a set of queries where we\n",
    "manually define which products are relevant.\n",
    "\n",
    "We create relevance judgements on a 0-3 scale:\n",
    "- **3** = highly relevant (exactly matches the query intent)\n",
    "- **2** = relevant (matches the category and use case)\n",
    "- **1** = partially relevant (related but not ideal)\n",
    "- **0** = not relevant\n",
    "\n",
    "We use the reranked results from Phase 3 as our candidate pool\n",
    "and assign relevance scores based on how well each result matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test set built: 8 queries\n",
      "\n",
      "Sample judgements for first query:\n",
      "Query: \"compact coffee maker for small kitchen\"\n",
      "  [2] Small Coffee Table White Modern Wood Mini Rectangle Coffee T\n",
      "  [2] Black & Decker DCM7 Cup-at-a-Time Personal 12-Ounce Coffeema\n",
      "  [2] Famiworths Single Serve Coffee Maker for K Cup and Ground Co\n",
      "  [2] Famiworths Single Serve Coffee Maker for K Cup and Ground Co\n",
      "  [2] Nesco Blade Coffee Grinder\n"
     ]
    }
   ],
   "source": [
    "def auto_judge_relevance(query: str, product: dict) -> int:\n",
    "    \"\"\"\n",
    "    Automatically assigns a relevance score (0-3) to a product\n",
    "    for a given query using keyword matching heuristics.\n",
    "\n",
    "    This is a proxy for human judgement â€” good enough for a\n",
    "    portfolio evaluation, not good enough for production.\n",
    "\n",
    "    Scoring:\n",
    "    3 â€” multiple query keywords in title AND product is right category\n",
    "    2 â€” some query keywords in title or description\n",
    "    1 â€” loosely related\n",
    "    0 â€” not relevant\n",
    "    \"\"\"\n",
    "    title = (product.get('title') or '').lower()\n",
    "    desc  = (product.get('description') or '').lower()\n",
    "    q     = query.lower()\n",
    "\n",
    "    # Extract meaningful query words (3+ chars, skip stopwords)\n",
    "    stopwords = {'for', 'the', 'and', 'with', 'under', 'best',\n",
    "                 'good', 'nice', 'great', 'some', 'that'}\n",
    "    q_words   = [w for w in q.split() if len(w) > 2 and w not in stopwords]\n",
    "\n",
    "    # Count how many query words appear in title\n",
    "    title_hits = sum(1 for w in q_words if w in title)\n",
    "    desc_hits  = sum(1 for w in q_words if w in desc)\n",
    "\n",
    "    total_words = len(q_words) if q_words else 1\n",
    "    title_ratio = title_hits / total_words\n",
    "\n",
    "    if title_ratio >= 0.6:\n",
    "        return 3   # highly relevant\n",
    "    elif title_ratio >= 0.3 or desc_hits >= 2:\n",
    "        return 2   # relevant\n",
    "    elif title_hits >= 1 or desc_hits >= 1:\n",
    "        return 1   # partially relevant\n",
    "    else:\n",
    "        return 0   # not relevant\n",
    "\n",
    "\n",
    "# Build test set from reranked results\n",
    "test_queries = []\n",
    "\n",
    "for result in reranked_results:\n",
    "    query    = result['query']\n",
    "    products = result['results']\n",
    "\n",
    "    # Assign relevance scores to each result\n",
    "    judgements = [\n",
    "        {\n",
    "            'asin'      : p['asin'],\n",
    "            'title'     : p['title'],\n",
    "            'relevance' : auto_judge_relevance(query, p),\n",
    "            'rerank_score': p.get('rerank_score', 0),\n",
    "            'faiss_score' : p.get('faiss_score', 0)\n",
    "        }\n",
    "        for p in products\n",
    "    ]\n",
    "\n",
    "    test_queries.append({\n",
    "        'query'     : query,\n",
    "        'judgements': judgements\n",
    "    })\n",
    "\n",
    "print(f'âœ… Test set built: {len(test_queries)} queries')\n",
    "print(f'\\nSample judgements for first query:')\n",
    "print(f'Query: \"{test_queries[0][\"query\"]}\"')\n",
    "for j in test_queries[0]['judgements']:\n",
    "    print(f'  [{j[\"relevance\"]}] {j[\"title\"][:60]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 â€” Implement MRR and NDCG\n",
    "\n",
    "Clean implementations of both metrics from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity checks:\n",
      "  Perfect ranking  [3,3,2,1,0] NDCG = 1.0000 (expect 1.0)\n",
      "  Reversed ranking [0,1,2,3,3] NDCG = 0.5884 (expect low)\n",
      "  MRR first pos    [3,0,0,0,0] MRR  = 1.0000 (expect 1.0)\n",
      "  MRR second pos   [0,3,0,0,0] MRR  = 0.5000 (expect 0.5)\n",
      "  MRR no relevant  [0,0,0,0,0] MRR  = 0.0000 (expect 0.0)\n",
      "\n",
      "âœ… Metric implementations verified.\n"
     ]
    }
   ],
   "source": [
    "def compute_mrr(relevance_scores: list[int], threshold: int = 1) -> float:\n",
    "    \"\"\"\n",
    "    Compute Reciprocal Rank for one query.\n",
    "\n",
    "    Args:\n",
    "        relevance_scores: List of relevance scores in ranked order\n",
    "                         e.g. [0, 3, 2, 1, 0]\n",
    "        threshold       : Minimum score to count as 'relevant'\n",
    "\n",
    "    Returns:\n",
    "        Reciprocal rank (1/position of first relevant result)\n",
    "        0.0 if no relevant results found\n",
    "    \"\"\"\n",
    "    for i, score in enumerate(relevance_scores, 1):  # positions are 1-indexed\n",
    "        if score >= threshold:\n",
    "            return 1.0 / i\n",
    "    return 0.0   # no relevant result found\n",
    "\n",
    "\n",
    "def compute_dcg(relevance_scores: list[int]) -> float:\n",
    "    \"\"\"\n",
    "    Compute Discounted Cumulative Gain.\n",
    "    Higher positions get more credit, lower positions get discounted.\n",
    "    DCG = sum of (2^relevance - 1) / log2(position + 1)\n",
    "    \"\"\"\n",
    "    return sum(\n",
    "        (2**rel - 1) / np.log2(i + 2)   # i+2 because positions are 0-indexed here\n",
    "        for i, rel in enumerate(relevance_scores)\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_ndcg(relevance_scores: list[int]) -> float:\n",
    "    \"\"\"\n",
    "    Compute Normalized DCG.\n",
    "    Divides actual DCG by ideal DCG (perfect ranking).\n",
    "    Result is always between 0 and 1.\n",
    "    \"\"\"\n",
    "    actual_dcg = compute_dcg(relevance_scores)\n",
    "\n",
    "    # Ideal DCG = DCG if results were sorted by relevance (best first)\n",
    "    ideal_dcg  = compute_dcg(sorted(relevance_scores, reverse=True))\n",
    "\n",
    "    if ideal_dcg == 0:\n",
    "        return 0.0   # no relevant results at all\n",
    "\n",
    "    return actual_dcg / ideal_dcg\n",
    "\n",
    "\n",
    "def mean_metric(values: list[float]) -> float:\n",
    "    \"\"\"Average a list of metric values.\"\"\"\n",
    "    return sum(values) / len(values) if values else 0.0\n",
    "\n",
    "\n",
    "# Quick sanity check\n",
    "print('Sanity checks:')\n",
    "print(f'  Perfect ranking  [3,3,2,1,0] NDCG = {compute_ndcg([3,3,2,1,0]):.4f} (expect 1.0)')\n",
    "print(f'  Reversed ranking [0,1,2,3,3] NDCG = {compute_ndcg([0,1,2,3,3]):.4f} (expect low)')\n",
    "print(f'  MRR first pos    [3,0,0,0,0] MRR  = {compute_mrr([3,0,0,0,0]):.4f} (expect 1.0)')\n",
    "print(f'  MRR second pos   [0,3,0,0,0] MRR  = {compute_mrr([0,3,0,0,0]):.4f} (expect 0.5)')\n",
    "print(f'  MRR no relevant  [0,0,0,0,0] MRR  = {compute_mrr([0,0,0,0,0]):.4f} (expect 0.0)')\n",
    "print('\\nâœ… Metric implementations verified.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 â€” Get FAISS-Only Results\n",
    "\n",
    "We need to run the FAISS-only pipeline for all test queries\n",
    "so we can compare it against the reranked results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS search complete for 8 queries\n"
     ]
    }
   ],
   "source": [
    "def faiss_search(query: str, top_k: int = 5) -> list[dict]:\n",
    "    \"\"\"Run FAISS-only search and return top_k results.\"\"\"\n",
    "    q_emb = embed_model.encode(\n",
    "        [query],\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=True\n",
    "    ).astype('float32')\n",
    "\n",
    "    scores, indices = product_index.search(q_emb, top_k)\n",
    "\n",
    "    results = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        p = product_metadata[idx].copy()\n",
    "        p['faiss_score'] = round(float(score), 4)\n",
    "        results.append(p)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Run FAISS search for all test queries\n",
    "faiss_results = {}\n",
    "for tq in test_queries:\n",
    "    query              = tq['query']\n",
    "    faiss_results[query] = faiss_search(query, top_k=5)\n",
    "\n",
    "print(f'âœ… FAISS search complete for {len(faiss_results)} queries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 â€” Compute Metrics for Both Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Metrics computed for 8 queries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>faiss_mrr</th>\n",
       "      <th>rerank_mrr</th>\n",
       "      <th>faiss_ndcg</th>\n",
       "      <th>rerank_ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>compact coffee maker for small kitchen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>non stick frying pan</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gift for someone who loves cooking</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7604</td>\n",
       "      <td>0.9808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>storage solution for small apartment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7745</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>durable water bottle for gym</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>budget friendly knife set for beginner cook</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>air fryer for family of four</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cute kitchen decor for modern home</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7992</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         query  faiss_mrr  rerank_mrr  \\\n",
       "0       compact coffee maker for small kitchen        1.0         1.0   \n",
       "1                         non stick frying pan        1.0         1.0   \n",
       "2           gift for someone who loves cooking        1.0         1.0   \n",
       "3         storage solution for small apartment        1.0         1.0   \n",
       "4                 durable water bottle for gym        1.0         1.0   \n",
       "5  budget friendly knife set for beginner cook        1.0         1.0   \n",
       "6                 air fryer for family of four        1.0         1.0   \n",
       "7           cute kitchen decor for modern home        1.0         1.0   \n",
       "\n",
       "   faiss_ndcg  rerank_ndcg  \n",
       "0      1.0000       1.0000  \n",
       "1      1.0000       1.0000  \n",
       "2      0.7604       0.9808  \n",
       "3      0.7745       1.0000  \n",
       "4      0.9438       1.0000  \n",
       "5      1.0000       1.0000  \n",
       "6      1.0000       1.0000  \n",
       "7      0.7992       1.0000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for tq in test_queries:\n",
    "    query = tq['query']\n",
    "\n",
    "    # â”€â”€ FAISS-only pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    faiss_products = faiss_results[query]\n",
    "    faiss_rel      = [auto_judge_relevance(query, p) for p in faiss_products]\n",
    "    faiss_mrr      = compute_mrr(faiss_rel)\n",
    "    faiss_ndcg     = compute_ndcg(faiss_rel)\n",
    "\n",
    "    # â”€â”€ Reranked pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Results are already ranked by rerank_score from Phase 3\n",
    "    reranked_products = next(\n",
    "        (r['results'] for r in reranked_results if r['query'] == query), []\n",
    "    )\n",
    "    rerank_rel  = [auto_judge_relevance(query, p) for p in reranked_products]\n",
    "    rerank_mrr  = compute_mrr(rerank_rel)\n",
    "    rerank_ndcg = compute_ndcg(rerank_rel)\n",
    "\n",
    "    # â”€â”€ Compute improvement â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    mrr_delta  = rerank_mrr  - faiss_mrr\n",
    "    ndcg_delta = rerank_ndcg - faiss_ndcg\n",
    "\n",
    "    rows.append({\n",
    "        'query'           : query,\n",
    "        'faiss_mrr'       : round(faiss_mrr,  4),\n",
    "        'rerank_mrr'      : round(rerank_mrr, 4),\n",
    "        'mrr_delta'       : round(mrr_delta,  4),\n",
    "        'faiss_ndcg'      : round(faiss_ndcg,  4),\n",
    "        'rerank_ndcg'     : round(rerank_ndcg, 4),\n",
    "        'ndcg_delta'      : round(ndcg_delta,  4),\n",
    "        'faiss_relevances' : faiss_rel,\n",
    "        'rerank_relevances': rerank_rel\n",
    "    })\n",
    "\n",
    "df_eval = pd.DataFrame(rows)\n",
    "print(f'âœ… Metrics computed for {len(df_eval)} queries')\n",
    "df_eval[['query', 'faiss_mrr', 'rerank_mrr', 'faiss_ndcg', 'rerank_ndcg']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 â€” Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                  SHOPSENSE EVALUATION RESULTS\n",
      "======================================================================\n",
      "Query                                       FAISS  Rerank   FAISS  Rerank\n",
      "                                              MRR     MRR    NDCG    NDCG\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "compact coffee maker for small kitchen      1.000   1.000   1.000   1.000\n",
      "non stick frying pan                        1.000   1.000   1.000   1.000\n",
      "gift for someone who loves cooking          1.000   1.000   0.760   0.981\n",
      "storage solution for small apartment        1.000   1.000   0.774   1.000\n",
      "durable water bottle for gym                1.000   1.000   0.944   1.000\n",
      "budget friendly knife set for beginner c    1.000   1.000   1.000   1.000\n",
      "air fryer for family of four                1.000   1.000   1.000   1.000\n",
      "cute kitchen decor for modern home          1.000   1.000   0.799   1.000\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "MEAN                                        1.000   1.000   0.910   0.998\n",
      "======================================================================\n",
      "\n",
      "MRR  improvement  from reranking: +0.0%\n",
      "NDCG improvement from reranking: +9.7%\n"
     ]
    }
   ],
   "source": [
    "# Compute aggregate metrics\n",
    "mean_faiss_mrr   = mean_metric(df_eval['faiss_mrr'].tolist())\n",
    "mean_rerank_mrr  = mean_metric(df_eval['rerank_mrr'].tolist())\n",
    "mean_faiss_ndcg  = mean_metric(df_eval['faiss_ndcg'].tolist())\n",
    "mean_rerank_ndcg = mean_metric(df_eval['rerank_ndcg'].tolist())\n",
    "\n",
    "mrr_improvement  = ((mean_rerank_mrr  - mean_faiss_mrr)  / mean_faiss_mrr  * 100\n",
    "                    if mean_faiss_mrr  > 0 else 0)\n",
    "ndcg_improvement = ((mean_rerank_ndcg - mean_faiss_ndcg) / mean_faiss_ndcg * 100\n",
    "                    if mean_faiss_ndcg > 0 else 0)\n",
    "\n",
    "print('=' * 70)\n",
    "print('                  SHOPSENSE EVALUATION RESULTS')\n",
    "print('=' * 70)\n",
    "print(f'{\"Query\":<42} {\"FAISS\":>6} {\"Rerank\":>7} {\"FAISS\":>7} {\"Rerank\":>7}')\n",
    "print(f'{\"\":<42} {\"MRR\":>6} {\"MRR\":>7} {\"NDCG\":>7} {\"NDCG\":>7}')\n",
    "print('â”€' * 70)\n",
    "\n",
    "for _, row in df_eval.iterrows():\n",
    "    q = row['query'][:40]\n",
    "    print(f\"{q:<42} {row['faiss_mrr']:>6.3f} {row['rerank_mrr']:>7.3f} \"\n",
    "          f\"{row['faiss_ndcg']:>7.3f} {row['rerank_ndcg']:>7.3f}\")\n",
    "\n",
    "print('â”€' * 70)\n",
    "print(f\"{'MEAN':<42} {mean_faiss_mrr:>6.3f} {mean_rerank_mrr:>7.3f} \"\n",
    "      f\"{mean_faiss_ndcg:>7.3f} {mean_rerank_ndcg:>7.3f}\")\n",
    "print('=' * 70)\n",
    "print()\n",
    "print(f'MRR  improvement  from reranking: {mrr_improvement:+.1f}%')\n",
    "print(f'NDCG improvement from reranking: {ndcg_improvement:+.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 â€” Per-Query Analysis\n",
    "\n",
    "Shows relevance scores for each position so you can see exactly\n",
    "how reranking changed the ordering for each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER-QUERY RELEVANCE BREAKDOWN\n",
      "(Relevance: 3=highly relevant, 2=relevant, 1=partial, 0=not relevant)\n",
      "\n",
      "âž¡ï¸  Query: \"compact coffee maker for small kitchen\"\n",
      "   FAISS only  : [2, 2, 2, 2, 2]  MRR=1.000  NDCG=1.000\n",
      "   + Reranking : [2, 2, 2, 2, 2]  MRR=1.000  NDCG=1.000\n",
      "\n",
      "âž¡ï¸  Query: \"non stick frying pan\"\n",
      "   FAISS only  : [3, 3, 3, 3, 3]  MRR=1.000  NDCG=1.000\n",
      "   + Reranking : [3, 3, 3, 3, 3]  MRR=1.000  NDCG=1.000\n",
      "\n",
      "âœ… Query: \"gift for someone who loves cooking\"\n",
      "   FAISS only  : [1, 1, 2, 1, 2]  MRR=1.000  NDCG=0.760\n",
      "   + Reranking : [2, 2, 1, 2, 1]  MRR=1.000  NDCG=0.981\n",
      "\n",
      "âœ… Query: \"storage solution for small apartment\"\n",
      "   FAISS only  : [1, 1, 2, 2, 1]  MRR=1.000  NDCG=0.774\n",
      "   + Reranking : [2, 2, 2, 2, 2]  MRR=1.000  NDCG=1.000\n",
      "\n",
      "âœ… Query: \"durable water bottle for gym\"\n",
      "   FAISS only  : [3, 2, 3, 2, 3]  MRR=1.000  NDCG=0.944\n",
      "   + Reranking : [3, 3, 3, 3, 2]  MRR=1.000  NDCG=1.000\n",
      "\n",
      "âž¡ï¸  Query: \"budget friendly knife set for beginner cook\"\n",
      "   FAISS only  : [2, 2, 2, 2, 2]  MRR=1.000  NDCG=1.000\n",
      "   + Reranking : [2, 2, 2, 2, 2]  MRR=1.000  NDCG=1.000\n",
      "\n",
      "âž¡ï¸  Query: \"air fryer for family of four\"\n",
      "   FAISS only  : [2, 2, 2, 2, 2]  MRR=1.000  NDCG=1.000\n",
      "   + Reranking : [2, 2, 2, 2, 2]  MRR=1.000  NDCG=1.000\n",
      "\n",
      "âœ… Query: \"cute kitchen decor for modern home\"\n",
      "   FAISS only  : [1, 3, 3, 3, 3]  MRR=1.000  NDCG=0.799\n",
      "   + Reranking : [3, 3, 3, 3, 3]  MRR=1.000  NDCG=1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('PER-QUERY RELEVANCE BREAKDOWN')\n",
    "print('(Relevance: 3=highly relevant, 2=relevant, 1=partial, 0=not relevant)\\n')\n",
    "\n",
    "for _, row in df_eval.iterrows():\n",
    "    q           = row['query']\n",
    "    f_rels      = row['faiss_relevances']\n",
    "    r_rels      = row['rerank_relevances']\n",
    "    improved    = 'âœ…' if row['ndcg_delta'] > 0 else ('âž¡ï¸ ' if row['ndcg_delta'] == 0 else 'âŒ')\n",
    "\n",
    "    print(f\"{improved} Query: \\\"{q}\\\"\")\n",
    "    print(f\"   FAISS only  : {f_rels}  MRR={row['faiss_mrr']:.3f}  NDCG={row['faiss_ndcg']:.3f}\")\n",
    "    print(f\"   + Reranking : {r_rels}  MRR={row['rerank_mrr']:.3f}  NDCG={row['rerank_ndcg']:.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 â€” Visual Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "âœ… matplotlib installed\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib -q\n",
    "print('âœ… matplotlib installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Plot saved â†’ data/evaluation_plot.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ml/9ppxtlpd5p59628p20mp4_dh0000gn/T/ipykernel_34628/2464790918.py:45: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  # non-interactive backend for VS Code\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('ShopSense â€” FAISS Only vs FAISS + Reranking', fontsize=14, fontweight='bold')\n",
    "\n",
    "queries_short = [q[:30] + '...' if len(q) > 30 else q\n",
    "                 for q in df_eval['query']]\n",
    "x = np.arange(len(queries_short))\n",
    "w = 0.35\n",
    "\n",
    "# â”€â”€ MRR plot â”€â”€\n",
    "ax1 = axes[0]\n",
    "ax1.bar(x - w/2, df_eval['faiss_mrr'],  w, label='FAISS Only',     color='#4C72B0', alpha=0.85)\n",
    "ax1.bar(x + w/2, df_eval['rerank_mrr'], w, label='FAISS + Rerank', color='#DD8452', alpha=0.85)\n",
    "ax1.axhline(mean_faiss_mrr,  color='#4C72B0', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax1.axhline(mean_rerank_mrr, color='#DD8452', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax1.set_title(f'MRR  (Mean: FAISS={mean_faiss_mrr:.3f}, Rerank={mean_rerank_mrr:.3f})')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(queries_short, rotation=45, ha='right', fontsize=7)\n",
    "ax1.set_ylim(0, 1.1)\n",
    "ax1.set_ylabel('MRR Score')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# â”€â”€ NDCG plot â”€â”€\n",
    "ax2 = axes[1]\n",
    "ax2.bar(x - w/2, df_eval['faiss_ndcg'],  w, label='FAISS Only',     color='#4C72B0', alpha=0.85)\n",
    "ax2.bar(x + w/2, df_eval['rerank_ndcg'], w, label='FAISS + Rerank', color='#DD8452', alpha=0.85)\n",
    "ax2.axhline(mean_faiss_ndcg,  color='#4C72B0', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax2.axhline(mean_rerank_ndcg, color='#DD8452', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax2.set_title(f'NDCG  (Mean: FAISS={mean_faiss_ndcg:.3f}, Rerank={mean_rerank_ndcg:.3f})')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(queries_short, rotation=45, ha='right', fontsize=7)\n",
    "ax2.set_ylim(0, 1.1)\n",
    "ax2.set_ylabel('NDCG Score')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = DATA_DIR / 'evaluation_plot.png'\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f'âœ… Plot saved â†’ {plot_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 â€” Save Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: data/evaluation_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results table (without the list columns)\n",
    "df_save = df_eval.drop(columns=['faiss_relevances', 'rerank_relevances'])\n",
    "csv_path = DATA_DIR / 'evaluation_results.csv'\n",
    "df_save.to_csv(csv_path, index=False)\n",
    "print(f'âœ… Saved: {csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 â€” README-Ready Summary\n",
    "Copy this directly into your GitHub README evaluation section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## ðŸ“Š Evaluation Results\n",
      "\n",
      "Evaluated on 8 queries using automated relevance judgements (0-3 scale).\n",
      "Metrics: MRR (Mean Reciprocal Rank) and NDCG@5 (Normalized Discounted Cumulative Gain).\n",
      "\n",
      "| Pipeline | MRR | NDCG@5 |\n",
      "|---|---|---|\n",
      "| FAISS Only | 1.000 | 0.910 |\n",
      "| FAISS + Cross-Encoder Reranking | 1.000 | 0.998 |\n",
      "| **Improvement** | **+0.0%** | **+9.7%** |\n",
      "\n",
      "### Per-Query Breakdown\n",
      "\n",
      "| Query | FAISS MRR | Rerank MRR | FAISS NDCG | Rerank NDCG |\n",
      "|---|---|---|---|---|\n",
      "| compact coffee maker for small kitchen | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| non stick frying pan | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| gift for someone who loves cooking | 1.000 | 1.000 | 0.760 | 0.981 |\n",
      "| storage solution for small apartment | 1.000 | 1.000 | 0.774 | 1.000 |\n",
      "| durable water bottle for gym | 1.000 | 1.000 | 0.944 | 1.000 |\n",
      "| budget friendly knife set for beginner cook | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| air fryer for family of four | 1.000 | 1.000 | 1.000 | 1.000 |\n",
      "| cute kitchen decor for modern home | 1.000 | 1.000 | 0.799 | 1.000 |\n",
      "\n",
      "âœ… README section saved â†’ data/evaluation_readme.md\n"
     ]
    }
   ],
   "source": [
    "readme_table = f\"\"\"## ðŸ“Š Evaluation Results\n",
    "\n",
    "Evaluated on {len(df_eval)} queries using automated relevance judgements (0-3 scale).\n",
    "Metrics: MRR (Mean Reciprocal Rank) and NDCG@5 (Normalized Discounted Cumulative Gain).\n",
    "\n",
    "| Pipeline | MRR | NDCG@5 |\n",
    "|---|---|---|\n",
    "| FAISS Only | {mean_faiss_mrr:.3f} | {mean_faiss_ndcg:.3f} |\n",
    "| FAISS + Cross-Encoder Reranking | {mean_rerank_mrr:.3f} | {mean_rerank_ndcg:.3f} |\n",
    "| **Improvement** | **{mrr_improvement:+.1f}%** | **{ndcg_improvement:+.1f}%** |\n",
    "\n",
    "### Per-Query Breakdown\n",
    "\n",
    "| Query | FAISS MRR | Rerank MRR | FAISS NDCG | Rerank NDCG |\n",
    "|---|---|---|---|---|\n",
    "\"\"\"\n",
    "\n",
    "for _, row in df_eval.iterrows():\n",
    "    readme_table += (\n",
    "        f\"| {row['query'][:45]} \"\n",
    "        f\"| {row['faiss_mrr']:.3f} \"\n",
    "        f\"| {row['rerank_mrr']:.3f} \"\n",
    "        f\"| {row['faiss_ndcg']:.3f} \"\n",
    "        f\"| {row['rerank_ndcg']:.3f} |\\n\"\n",
    "    )\n",
    "\n",
    "print(readme_table)\n",
    "\n",
    "# Save to file\n",
    "readme_path = DATA_DIR / 'evaluation_readme.md'\n",
    "with open(readme_path, 'w') as f:\n",
    "    f.write(readme_table)\n",
    "print(f'âœ… README section saved â†’ {readme_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
