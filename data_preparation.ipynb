{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase 1: Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "✅ Done. Now restart the kernel before continuing.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install datasets==2.17.0 -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 — Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "✅ Dependencies installed.\n"
     ]
    }
   ],
   "source": [
    "# Run this once. If you're using a virtual env, activate it first in the VS Code terminal:\n",
    "# python -m venv venv\n",
    "# Windows  : venv\\Scripts\\activate\n",
    "# Mac/Linux: source venv/bin/activate\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install datasets pandas tqdm -q\n",
    "print('✅ Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 — Create Local Folder Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Folder structure ready\n",
      "   BASE : /Users/rithikabaskaran/MyFiles/ShopSense\n",
      "   DATA : /Users/rithikabaskaran/MyFiles/ShopSense/data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# All paths are relative to wherever this notebook lives\n",
    "BASE_DIR  = Path('.')          # shopsense/\n",
    "DATA_DIR  = BASE_DIR / 'data'  # shopsense/data/\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create .gitignore so large data files don't get pushed to GitHub\n",
    "gitignore_path = BASE_DIR / '.gitignore'\n",
    "if not gitignore_path.exists():\n",
    "    gitignore_path.write_text(\n",
    "        '# Data files (too large for GitHub)\\n'\n",
    "        'data/\\n'\n",
    "        'models/\\n'\n",
    "        '__pycache__/\\n'\n",
    "        '.env\\n'\n",
    "        'venv/\\n'\n",
    "        '*.pyc\\n'\n",
    "    )\n",
    "    print('✅ .gitignore created')\n",
    "\n",
    "print(f'✅ Folder structure ready')\n",
    "print(f'   BASE : {BASE_DIR.resolve()}')\n",
    "print(f'   DATA : {DATA_DIR.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 — Configuration\n",
    "Only thing you might want to change is `CATEGORY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category    : Home_and_Kitchen\n",
      "Max products: 10,000\n"
     ]
    }
   ],
   "source": [
    "# ── CONFIG ──────────────────────────────────────────────────\n",
    "CATEGORY              = 'Home_and_Kitchen'  \n",
    "MAX_PRODUCTS          = 10_000\n",
    "MAX_REVIEWS_PER_PRODUCT = 10\n",
    "MIN_REVIEWS           = 5\n",
    "MIN_DESCRIPTION_LEN   = 50\n",
    "PRODUCT_SCAN_LIMIT    = 150_000\n",
    "REVIEW_SCAN_LIMIT     = 500_000\n",
    "# ────────────────────────────────────────────────────────────\n",
    "\n",
    "print(f'Category    : {CATEGORY}')\n",
    "print(f'Max products: {MAX_PRODUCTS:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 — Load Product Metadata (Streaming)\n",
    "Streaming means it never loads the full dataset into RAM — safe for local machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets version: 2.17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 39.6kB [00:00, 53.7MB/s]\n",
      "Downloading readme: 30.3kB [00:00, 33.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Product stream ready.\n"
     ]
    }
   ],
   "source": [
    "import sys, shutil, os\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "print(f'datasets version: {datasets.__version__}')  # should show 2.17.0\n",
    "\n",
    "meta_dataset = load_dataset(\n",
    "    'McAuley-Lab/Amazon-Reviews-2023',\n",
    "    f'raw_meta_{CATEGORY}',\n",
    "    split='full',\n",
    "    streaming=True,\n",
    "    trust_remote_code=True   # needed again with 2.17.0\n",
    ")\n",
    "\n",
    "print('✅ Product stream ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 — Extract & Clean Product Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning up to 150,000 raw records to find 10,000 clean products...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 12599/150000 [00:03<00:37, 3638.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Collected 10,000 clean product records.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def extract_description(item):\n",
    "    \"\"\"Combine title + bullet features + description into one rich text field.\"\"\"\n",
    "    parts = []\n",
    "\n",
    "    title = item.get('title', '') or ''\n",
    "    parts.append(title.strip())\n",
    "\n",
    "    features = item.get('features', []) or []\n",
    "    if features:\n",
    "        parts.append(' '.join(str(f) for f in features[:5]))\n",
    "\n",
    "    description = item.get('description', []) or []\n",
    "    if description:\n",
    "        parts.append(' '.join(str(d) for d in description[:3]))\n",
    "\n",
    "    return ' '.join(parts).strip()\n",
    "\n",
    "\n",
    "def safe_float(val, default=None):\n",
    "    try:\n",
    "        return float(str(val).replace('$', '').replace(',', '').strip())\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "records   = []\n",
    "seen_asins = set()\n",
    "\n",
    "print(f'Scanning up to {PRODUCT_SCAN_LIMIT:,} raw records to find {MAX_PRODUCTS:,} clean products...')\n",
    "\n",
    "for i, item in enumerate(tqdm(meta_dataset, total=PRODUCT_SCAN_LIMIT)):\n",
    "    if i >= PRODUCT_SCAN_LIMIT or len(records) >= MAX_PRODUCTS:\n",
    "        break\n",
    "\n",
    "    asin = item.get('parent_asin') or item.get('asin', '')\n",
    "    if not asin or asin in seen_asins:\n",
    "        continue\n",
    "\n",
    "    title = (item.get('title') or '').strip()\n",
    "    if not title:\n",
    "        continue\n",
    "\n",
    "    description = extract_description(item)\n",
    "    if len(description) < MIN_DESCRIPTION_LEN:\n",
    "        continue\n",
    "\n",
    "    price        = safe_float(item.get('price'))\n",
    "    rating       = safe_float(item.get('average_rating'))\n",
    "    rating_count = item.get('rating_number') or 0\n",
    "\n",
    "    if not rating or not rating_count or rating_count < MIN_REVIEWS:\n",
    "        continue\n",
    "\n",
    "    seen_asins.add(asin)\n",
    "    records.append({\n",
    "        'asin'         : asin,\n",
    "        'title'        : title,\n",
    "        'description'  : description,\n",
    "        'category'     : CATEGORY.replace('_', ' & '),\n",
    "        'price'        : price,\n",
    "        'rating'       : rating,\n",
    "        'rating_count' : int(rating_count),\n",
    "        'store'        : item.get('store', ''),\n",
    "        'main_image'   : '',  # skipping image field — not needed for embeddings\n",
    "    })\n",
    "\n",
    "print(f'\\n✅ Collected {len(records):,} clean product records.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 — Inspect Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape : (10000, 9)\n",
      "Columns: ['asin', 'title', 'description', 'category', 'price', 'rating', 'rating_count', 'store', 'main_image']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>store</th>\n",
       "      <th>main_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07R3DYMH6</td>\n",
       "      <td>Set of 4 Irish Coffee Glass Mugs Footed 10.5 o...</td>\n",
       "      <td>Set of 4 Irish Coffee Glass Mugs Footed 10.5 o...</td>\n",
       "      <td>Home &amp; and &amp; Kitchen</td>\n",
       "      <td>24.95</td>\n",
       "      <td>4.6</td>\n",
       "      <td>18</td>\n",
       "      <td>LavoHome</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0BNZ8Q7YT</td>\n",
       "      <td>Foaming Soap Dispenser Thick Ceramic Foam Hand...</td>\n",
       "      <td>Foaming Soap Dispenser Thick Ceramic Foam Hand...</td>\n",
       "      <td>Home &amp; and &amp; Kitchen</td>\n",
       "      <td>24.99</td>\n",
       "      <td>4.4</td>\n",
       "      <td>135</td>\n",
       "      <td>rejomiik</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00KKU8HTG</td>\n",
       "      <td>jersey seating 2 x Vinyl Air Lift Adjustable S...</td>\n",
       "      <td>jersey seating 2 x Vinyl Air Lift Adjustable S...</td>\n",
       "      <td>Home &amp; and &amp; Kitchen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>167</td>\n",
       "      <td>jersey seating®</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                              title  \\\n",
       "0  B07R3DYMH6  Set of 4 Irish Coffee Glass Mugs Footed 10.5 o...   \n",
       "1  B0BNZ8Q7YT  Foaming Soap Dispenser Thick Ceramic Foam Hand...   \n",
       "2  B00KKU8HTG  jersey seating 2 x Vinyl Air Lift Adjustable S...   \n",
       "\n",
       "                                         description              category  \\\n",
       "0  Set of 4 Irish Coffee Glass Mugs Footed 10.5 o...  Home & and & Kitchen   \n",
       "1  Foaming Soap Dispenser Thick Ceramic Foam Hand...  Home & and & Kitchen   \n",
       "2  jersey seating 2 x Vinyl Air Lift Adjustable S...  Home & and & Kitchen   \n",
       "\n",
       "   price  rating  rating_count            store main_image  \n",
       "0  24.95     4.6            18         LavoHome             \n",
       "1  24.99     4.4           135         rejomiik             \n",
       "2    NaN     4.3           167  jersey seating®             "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_products = pd.DataFrame(records)\n",
    "\n",
    "print(f'Shape : {df_products.shape}')\n",
    "print(f'Columns: {df_products.columns.tolist()}')\n",
    "df_products.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Key Stats ===\n",
      "Products            : 10,000\n",
      "With price          : 5,792 (57.9%)\n",
      "Price range         : $1.53 — $2699.00\n",
      "Avg rating          : 4.31\n",
      "Avg description len : 1073 chars\n",
      "\n",
      "=== Price Distribution ===\n",
      "price_bucket\n",
      "<$10         737\n",
      "$10-25      2460\n",
      "$25-50      1450\n",
      "$50-100      615\n",
      "$100-200     331\n",
      "$200+        199\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('=== Key Stats ===')\n",
    "print(f\"Products            : {len(df_products):,}\")\n",
    "print(f\"With price          : {df_products['price'].notna().sum():,} ({df_products['price'].notna().mean()*100:.1f}%)\")\n",
    "print(f\"Price range         : ${df_products['price'].min():.2f} — ${df_products['price'].max():.2f}\")\n",
    "print(f\"Avg rating          : {df_products['rating'].mean():.2f}\")\n",
    "print(f\"Avg description len : {df_products['description'].str.len().mean():.0f} chars\")\n",
    "\n",
    "print('\\n=== Price Distribution ===')\n",
    "bins   = [0, 10, 25, 50, 100, 200, float('inf')]\n",
    "labels = ['<$10', '$10-25', '$25-50', '$50-100', '$100-200', '$200+']\n",
    "df_products['price_bucket'] = pd.cut(df_products['price'], bins=bins, labels=labels)\n",
    "print(df_products['price_bucket'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 — Save Products CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ products_clean.csv saved (12.1 MB) → /Users/rithikabaskaran/MyFiles/ShopSense/data/products_clean.csv\n"
     ]
    }
   ],
   "source": [
    "df_save = df_products.drop(columns=['price_bucket'])\n",
    "\n",
    "products_path = DATA_DIR / 'products_clean.csv'\n",
    "df_save.to_csv(products_path, index=False)\n",
    "\n",
    "size_mb = products_path.stat().st_size / (1024 * 1024)\n",
    "print(f'✅ products_clean.csv saved ({size_mb:.1f} MB) → {products_path.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 — Load Reviews for These Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will filter reviews to 10,000 product ASINs\n",
      "\n",
      "Opening review stream for: Home_and_Kitchen\n",
      "✅ Review stream ready.\n"
     ]
    }
   ],
   "source": [
    "valid_asins = set(df_products['asin'].tolist())\n",
    "print(f'Will filter reviews to {len(valid_asins):,} product ASINs')\n",
    "\n",
    "print(f'\\nOpening review stream for: {CATEGORY}')\n",
    "review_dataset = load_dataset(\n",
    "    'McAuley-Lab/Amazon-Reviews-2023',\n",
    "    f'raw_review_{CATEGORY}',\n",
    "    split='full',\n",
    "    streaming=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "print('✅ Review stream ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning up to 500,000 review records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500000/500000 [00:07<00:00, 63298.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Collected 5,566 reviews across 2,003 products.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "review_records = []\n",
    "review_counts  = {}   # asin → count\n",
    "MIN_REVIEW_LEN = 30\n",
    "\n",
    "print(f'Scanning up to {REVIEW_SCAN_LIMIT:,} review records...')\n",
    "\n",
    "for i, review in enumerate(tqdm(review_dataset, total=REVIEW_SCAN_LIMIT)):\n",
    "    if i >= REVIEW_SCAN_LIMIT:\n",
    "        break\n",
    "\n",
    "    asin = review.get('parent_asin') or review.get('asin', '')\n",
    "    if asin not in valid_asins:\n",
    "        continue\n",
    "    if review_counts.get(asin, 0) >= MAX_REVIEWS_PER_PRODUCT:\n",
    "        continue\n",
    "\n",
    "    text = (review.get('text') or '').strip()\n",
    "    if len(text) < MIN_REVIEW_LEN:\n",
    "        continue\n",
    "\n",
    "    review_records.append({\n",
    "        'asin'             : asin,\n",
    "        'review_title'     : (review.get('title') or '').strip(),\n",
    "        'review_text'      : text,\n",
    "        'rating'           : safe_float(review.get('rating'), default=0),\n",
    "        'helpful_vote'     : review.get('helpful_vote', 0) or 0,\n",
    "        'verified_purchase': review.get('verified_purchase', False)\n",
    "    })\n",
    "    review_counts[asin] = review_counts.get(asin, 0) + 1\n",
    "\n",
    "print(f'\\n✅ Collected {len(review_records):,} reviews across {len(review_counts):,} products.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 — Inspect & Save Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Review Stats ===\n",
      "Total reviews       : 5,566\n",
      "Products covered    : 2,003 / 10,000\n",
      "Avg reviews/product : 2.8\n",
      "Avg review length   : 268 chars\n",
      "Verified purchases  : 82.2%\n",
      "\n",
      "Rating distribution:\n",
      "rating\n",
      "1.0     299\n",
      "2.0     239\n",
      "3.0     427\n",
      "4.0     808\n",
      "5.0    3793\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_reviews = pd.DataFrame(review_records)\n",
    "\n",
    "print('=== Review Stats ===')\n",
    "print(f\"Total reviews       : {len(df_reviews):,}\")\n",
    "print(f\"Products covered    : {df_reviews['asin'].nunique():,} / {len(valid_asins):,}\")\n",
    "print(f\"Avg reviews/product : {len(df_reviews) / df_reviews['asin'].nunique():.1f}\")\n",
    "print(f\"Avg review length   : {df_reviews['review_text'].str.len().mean():.0f} chars\")\n",
    "print(f\"Verified purchases  : {df_reviews['verified_purchase'].mean()*100:.1f}%\")\n",
    "print(f\"\\nRating distribution:\")\n",
    "print(df_reviews['rating'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ reviews_clean.csv saved (1.7 MB) → /Users/rithikabaskaran/MyFiles/ShopSense/data/reviews_clean.csv\n"
     ]
    }
   ],
   "source": [
    "reviews_path = DATA_DIR / 'reviews_clean.csv'\n",
    "df_reviews.to_csv(reviews_path, index=False)\n",
    "\n",
    "size_mb = reviews_path.stat().st_size / (1024 * 1024)\n",
    "print(f'✅ reviews_clean.csv saved ({size_mb:.1f} MB) → {reviews_path.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 — Save Product ASINs Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 10,000 ASINs saved → /Users/rithikabaskaran/MyFiles/ShopSense/data/product_ids.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "asin_list  = df_products['asin'].tolist()\n",
    "asin_path  = DATA_DIR / 'product_ids.json'\n",
    "\n",
    "with open(asin_path, 'w') as f:\n",
    "    json.dump(asin_list, f)\n",
    "\n",
    "print(f'✅ {len(asin_list):,} ASINs saved → {asin_path.resolve()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 — Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "         PHASE 1 COMPLETE — SUMMARY\n",
      "=======================================================\n",
      "  Category           : Home_and_Kitchen\n",
      "  Products saved     : 10,000\n",
      "  Reviews saved      : 5,566\n",
      "  Products w/ reviews: 2,003\n",
      "\n",
      "  Files created:\n",
      "    ✅ data/products_clean.csv (12402 KB)\n",
      "    ✅ data/reviews_clean.csv (1726 KB)\n",
      "    ✅ data/product_ids.json (137 KB)\n",
      "\n",
      "  ➡️  Next: Phase 2 — Semantic Retrieval with FAISS\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "print('=' * 55)\n",
    "print('         PHASE 1 COMPLETE — SUMMARY')\n",
    "print('=' * 55)\n",
    "print(f'  Category           : {CATEGORY}')\n",
    "print(f'  Products saved     : {len(df_products):,}')\n",
    "print(f'  Reviews saved      : {len(df_reviews):,}')\n",
    "print(f'  Products w/ reviews: {df_reviews[\"asin\"].nunique():,}')\n",
    "print()\n",
    "print('  Files created:')\n",
    "for fname in ['products_clean.csv', 'reviews_clean.csv', 'product_ids.json']:\n",
    "    fpath = DATA_DIR / fname\n",
    "    size_kb = fpath.stat().st_size / 1024\n",
    "    print(f'    ✅ data/{fname} ({size_kb:.0f} KB)')\n",
    "print()\n",
    "print('  ➡️  Next: Phase 2 — Semantic Retrieval with FAISS')\n",
    "print('=' * 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Sample Peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 3 Sample Products ===\n",
      "\n",
      "ASIN   : B08RP93QSX\n",
      "Title  : Cubiker Computer Home Office Desk with Drawers, 40 Inch Small Desk Study Writing\n",
      "Price  : $99.99\n",
      "Rating : 4.5 ⭐ (2,857 reviews)\n",
      "Desc   : Cubiker Computer Home Office Desk with Drawers, 40 Inch Small Desk Study Writing Table, Modern Simple PC Desk, Black Modern Confident Style: Cubiker o...\n",
      "------------------------------------------------------------\n",
      "ASIN   : B09Y31JYHK\n",
      "Title  : Halloween Spider Net Tree Skirt, Seasonal Tree Mat Holiday Party Supplies Orname\n",
      "Price  : $14.99\n",
      "Rating : 4.8 ⭐ (106 reviews)\n",
      "Desc   : Halloween Spider Net Tree Skirt, Seasonal Tree Mat Holiday Party Supplies Ornaments Indoor Outdoor Decorations for Trees 48 Inches (Silver, 48 in) Uni...\n",
      "------------------------------------------------------------\n",
      "ASIN   : B0BLSB5LVH\n",
      "Title  : Swiss Ortho Sleep, Bamboo 12\" Inch Certified Independently & Individually Wrappe\n",
      "Price  : $259.99\n",
      "Rating : 4.2 ⭐ (5,183 reviews)\n",
      "Desc   : Swiss Ortho Sleep, Bamboo 12\" Inch Certified Independently & Individually Wrapped Pocketed Encased Coil Pocket Spring Contour Mattress - Queen, Plush ...\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('=== 3 Sample Products ===\\n')\n",
    "for _, row in df_products.sample(3, random_state=42).iterrows():\n",
    "    print(f\"ASIN   : {row['asin']}\")\n",
    "    print(f\"Title  : {row['title'][:80]}\")\n",
    "    print(f\"Price  : {'$'+str(row['price']) if row['price'] else 'N/A'}\")\n",
    "    print(f\"Rating : {row['rating']} ⭐ ({row['rating_count']:,} reviews)\")\n",
    "    print(f\"Desc   : {row['description'][:150]}...\")\n",
    "    print('-' * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
