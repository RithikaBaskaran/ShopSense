{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: LangGraph Agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 â€” Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "âœ… Dependencies installed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install langgraph langchain langchain-groq sentence-transformers faiss-cpu pandas numpy python-dotenv groq -q\n",
    "print('âœ… Dependencies installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 â€” Load Environment + All Phase 2/3/4 Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rithikabaskaran/MyFiles/ShopSense/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 2308.79it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Product index  : 10,000 vectors\n",
      "âœ… Review index   : 3,008 vectors\n",
      "âœ… Products loaded: 10,000\n",
      "âœ… Review chunks  : 3,008\n",
      "âœ… Groq model     : llama-3.1-8b-instant\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "\n",
    "# â”€â”€ Load embedding model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print('Loading embedding model...')\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# â”€â”€ Load product FAISS index + metadata (Phase 2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "product_index = faiss.read_index(str(DATA_DIR / 'faiss_index.bin'))\n",
    "with open(DATA_DIR / 'faiss_metadata.json') as f:\n",
    "    product_metadata = json.load(f)\n",
    "\n",
    "# â”€â”€ Load review FAISS index + metadata (Phase 4) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "review_index = faiss.read_index(str(DATA_DIR / 'reviews_faiss_index.bin'))\n",
    "with open(DATA_DIR / 'reviews_metadata.json') as f:\n",
    "    review_chunks = json.load(f)\n",
    "\n",
    "# â”€â”€ Load products dataframe â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_products = pd.read_csv(DATA_DIR / 'products_clean.csv')\n",
    "median_price = df_products['price'].median()\n",
    "\n",
    "# â”€â”€ Groq client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "groq_client = Groq(api_key=os.getenv('GROQ_API_KEY'))\n",
    "GROQ_MODEL  = 'llama-3.1-8b-instant'\n",
    "\n",
    "print(f'âœ… Product index  : {product_index.ntotal:,} vectors')\n",
    "print(f'âœ… Review index   : {review_index.ntotal:,} vectors')\n",
    "print(f'âœ… Products loaded: {len(product_metadata):,}')\n",
    "print(f'âœ… Review chunks  : {len(review_chunks):,}')\n",
    "print(f'âœ… Groq model     : {GROQ_MODEL}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 â€” Define the Three Agent Tools\n",
    "\n",
    "Tools are just Python functions. The agent (LLM) decides which one to call.\n",
    "Each tool does one specific job and returns a result the agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Three agent tools defined:\n",
      "   ğŸ” search_tool  â€” semantic product search\n",
      "   ğŸ”§ filter_tool  â€” price / rating / keyword filtering\n",
      "   â“ clarify_tool â€” follow-up question for vague queries\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ TOOL 1: Search Tool â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Searches products using FAISS semantic search.\n",
    "# This is the main tool â€” called for almost every query.\n",
    "\n",
    "def search_tool(query: str, top_k: int = 20) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Semantic product search using FAISS.\n",
    "    Returns top_k most relevant products for the query.\n",
    "    \"\"\"\n",
    "    query_emb = embed_model.encode(\n",
    "        [query],\n",
    "        normalize_embeddings=True,\n",
    "        convert_to_numpy=True\n",
    "    ).astype('float32')\n",
    "\n",
    "    scores, indices = product_index.search(query_emb, top_k)\n",
    "\n",
    "    results = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        product = product_metadata[idx].copy()\n",
    "        product['similarity_score'] = round(float(score), 4)\n",
    "        # Fill NaN prices with median\n",
    "        if not product.get('price') or str(product.get('price')) == 'nan':\n",
    "            product['price'] = median_price\n",
    "        results.append(product)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# â”€â”€ TOOL 2: Filter Tool â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Filters a list of products by price, rating, or keyword.\n",
    "# Called AFTER search_tool when the user specifies constraints.\n",
    "\n",
    "def filter_tool(\n",
    "    products: list[dict],\n",
    "    max_price: float = None,\n",
    "    min_price: float = None,\n",
    "    min_rating: float = None,\n",
    "    keyword: str = None\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Filter products by price range, minimum rating, or keyword.\n",
    "    Always returns at least 3 results by relaxing filters if needed.\n",
    "    \"\"\"\n",
    "    filtered = products\n",
    "\n",
    "    if max_price is not None:\n",
    "        filtered = [p for p in filtered if p.get('price', 0) <= max_price]\n",
    "    if min_price is not None:\n",
    "        filtered = [p for p in filtered if p.get('price', 0) >= min_price]\n",
    "    if min_rating is not None:\n",
    "        filtered = [p for p in filtered if p.get('rating', 0) >= min_rating]\n",
    "    if keyword is not None:\n",
    "        kw = keyword.lower()\n",
    "        filtered = [\n",
    "            p for p in filtered\n",
    "            if kw in p.get('title', '').lower()\n",
    "            or kw in p.get('description', '').lower()\n",
    "        ]\n",
    "\n",
    "    # Safety fallback â€” if too few results, relax filters\n",
    "    if len(filtered) < 3:\n",
    "        filtered = products[:10]\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "# â”€â”€ TOOL 3: Clarify Tool â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Used when the query is too vague to search meaningfully.\n",
    "# Returns a follow-up question for the user instead of results.\n",
    "\n",
    "def clarify_tool(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a clarifying question when the user query is too vague.\n",
    "    Returns a question string to ask the user.\n",
    "    \"\"\"\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=GROQ_MODEL,\n",
    "        messages=[{\n",
    "            'role': 'user',\n",
    "            'content': f\"\"\"A user typed this shopping query: \"{query}\"\n",
    "\n",
    "This query is too vague to search for products effectively.\n",
    "Generate ONE short, friendly follow-up question to clarify what they need.\n",
    "Focus on the most important missing detail (budget, use case, or specific type).\n",
    "Keep it under 20 words. Just the question, no preamble.\"\"\"\n",
    "        }],\n",
    "        max_tokens=50,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "print('âœ… Three agent tools defined:')\n",
    "print('   ğŸ” search_tool  â€” semantic product search')\n",
    "print('   ğŸ”§ filter_tool  â€” price / rating / keyword filtering')\n",
    "print('   â“ clarify_tool â€” follow-up question for vague queries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 â€” Define Agent State\n",
    "\n",
    "The agent needs to remember things as it moves through its reasoning steps.\n",
    "We store everything in a **state dictionary** that gets passed between nodes.\n",
    "Think of it as the agent's short-term memory for one conversation turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AgentState defined.\n",
      "   Fields: query, intent, filters, search_results,\n",
      "           final_results, clarify_question, explanation, needs_clarification\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Optional\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    The agent's memory â€” passed between every node in the graph.\n",
    "\n",
    "    Fields:\n",
    "        query         : The original user message\n",
    "        intent        : What the agent decided the user wants\n",
    "                        ('search', 'filter', 'clarify')\n",
    "        filters       : Any constraints extracted from the query\n",
    "                        e.g. {'max_price': 30, 'min_rating': 4.0}\n",
    "        search_results: Raw results from search_tool (top 20)\n",
    "        final_results : Final results after filtering (top 5)\n",
    "        clarify_question: Follow-up question if query was vague\n",
    "        explanation   : Agent's explanation of its recommendations\n",
    "        needs_clarification: True if agent wants to ask user something\n",
    "    \"\"\"\n",
    "    query               : str\n",
    "    intent              : Optional[str]\n",
    "    filters             : Optional[dict]\n",
    "    search_results      : Optional[list]\n",
    "    final_results       : Optional[list]\n",
    "    clarify_question    : Optional[str]\n",
    "    explanation         : Optional[str]\n",
    "    needs_clarification : bool\n",
    "\n",
    "print('âœ… AgentState defined.')\n",
    "print('   Fields: query, intent, filters, search_results,')\n",
    "print('           final_results, clarify_question, explanation, needs_clarification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 â€” Define the Graph Nodes\n",
    "\n",
    "Each node is a function that:\n",
    "1. Receives the current state\n",
    "2. Does one specific job\n",
    "3. Returns an updated state\n",
    "\n",
    "Our graph has 4 nodes:\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   ANALYZE   â”‚â”€â”€â”€â”€â–¶â”‚    SEARCH    â”‚â”€â”€â”€â”€â–¶â”‚   FILTER    â”‚â”€â”€â”€â”€â–¶â”‚   EXPLAIN   â”‚\n",
    "â”‚  (intent +  â”‚     â”‚ (FAISS top  â”‚     â”‚ (apply user â”‚     â”‚ (generate   â”‚\n",
    "â”‚   filters)  â”‚     â”‚    20)      â”‚     â”‚ constraints)â”‚     â”‚ explanation)â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "       â”‚\n",
    "       â”‚ (if vague)\n",
    "       â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   CLARIFY   â”‚\n",
    "â”‚ (ask user   â”‚\n",
    "â”‚  question)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Five nodes defined:\n",
      "   1. analyze_node  â€” extract intent + filters\n",
      "   2. clarify_node  â€” ask follow-up if vague\n",
      "   3. search_node   â€” FAISS semantic search\n",
      "   4. filter_node   â€” apply constraints\n",
      "   5. explain_node  â€” generate explanation\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€ NODE 1: Analyze â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# The brain of the agent. Looks at the user's query and decides:\n",
    "# - Is the query clear enough to search? Or too vague?\n",
    "# - What filters did the user mention (price, rating)?\n",
    "# - What is the user actually looking for?\n",
    "\n",
    "def analyze_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Analyzes the user query to extract intent and filters.\n",
    "    Decides whether to search or ask for clarification.\n",
    "    \"\"\"\n",
    "    query = state['query']\n",
    "\n",
    "    prompt = f\"\"\"You are a shopping assistant analyzing a user query.\n",
    "\n",
    "User query: \"{query}\"\n",
    "\n",
    "Analyze this query and respond with a JSON object containing:\n",
    "{{\n",
    "  \"intent\": \"search\" or \"clarify\",\n",
    "  \"needs_clarification\": true or false,\n",
    "  \"search_query\": \"refined search query to use (improve if needed)\",\n",
    "  \"filters\": {{\n",
    "    \"max_price\": null or number,\n",
    "    \"min_price\": null or number,\n",
    "    \"min_rating\": null or number,\n",
    "    \"keyword\": null or string\n",
    "  }},\n",
    "  \"reasoning\": \"one sentence explaining your decision\"\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Set intent to \"clarify\" ONLY if the query is extremely vague (e.g. \"something nice\", \"a good thing\")\n",
    "- Extract price from phrases like \"under $30\", \"less than 50 dollars\", \"budget\"\n",
    "- Extract rating from phrases like \"highly rated\", \"4 stars and above\", \"top rated\"\n",
    "- Improve the search_query to be more specific if needed\n",
    "- Respond with valid JSON only\"\"\"\n",
    "\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=GROQ_MODEL,\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        max_tokens=200,\n",
    "        temperature=0.1   # very low â€” we want consistent structured output\n",
    "    )\n",
    "\n",
    "    raw = response.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        clean   = re.sub(r'```json|```', '', raw).strip()\n",
    "        parsed  = json.loads(clean)\n",
    "        filters = parsed.get('filters', {})\n",
    "\n",
    "        return {\n",
    "            **state,\n",
    "            'intent'             : parsed.get('intent', 'search'),\n",
    "            'needs_clarification': parsed.get('needs_clarification', False),\n",
    "            'query'              : parsed.get('search_query', query),\n",
    "            'filters'            : {\n",
    "                'max_price' : filters.get('max_price'),\n",
    "                'min_price' : filters.get('min_price'),\n",
    "                'min_rating': filters.get('min_rating'),\n",
    "                'keyword'   : filters.get('keyword')\n",
    "            }\n",
    "        }\n",
    "    except Exception:\n",
    "        # If JSON parsing fails, default to search with no filters\n",
    "        return {\n",
    "            **state,\n",
    "            'intent'             : 'search',\n",
    "            'needs_clarification': False,\n",
    "            'filters'            : {}\n",
    "        }\n",
    "\n",
    "\n",
    "# â”€â”€ NODE 2: Clarify â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Only reached if analyze_node decided the query was too vague.\n",
    "# Generates a follow-up question for the user.\n",
    "\n",
    "def clarify_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generates a clarifying question for vague queries.\"\"\"\n",
    "    question = clarify_tool(state['query'])\n",
    "    return {\n",
    "        **state,\n",
    "        'clarify_question': question\n",
    "    }\n",
    "\n",
    "\n",
    "# â”€â”€ NODE 3: Search â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Calls the FAISS search tool with the (possibly refined) query.\n",
    "# Gets top 20 candidates.\n",
    "\n",
    "def search_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Performs semantic search using FAISS.\"\"\"\n",
    "    results = search_tool(state['query'], top_k=20)\n",
    "    return {\n",
    "        **state,\n",
    "        'search_results': results\n",
    "    }\n",
    "\n",
    "\n",
    "# â”€â”€ NODE 4: Filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Applies any filters extracted by analyze_node.\n",
    "# Narrows 20 candidates down to top 5.\n",
    "\n",
    "def filter_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Applies price/rating/keyword filters and selects top 5.\"\"\"\n",
    "    filters  = state.get('filters') or {}\n",
    "    products = state.get('search_results') or []\n",
    "\n",
    "    filtered = filter_tool(\n",
    "        products,\n",
    "        max_price  = filters.get('max_price'),\n",
    "        min_price  = filters.get('min_price'),\n",
    "        min_rating = filters.get('min_rating'),\n",
    "        keyword    = filters.get('keyword')\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        'final_results': filtered[:5]\n",
    "    }\n",
    "\n",
    "\n",
    "# â”€â”€ NODE 5: Explain â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# The final node. Takes the top 5 results and generates a\n",
    "# natural language explanation of WHY each product was recommended.\n",
    "\n",
    "def explain_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generates a natural language explanation for the recommendations.\"\"\"\n",
    "    query   = state['query']\n",
    "    results = state.get('final_results') or []\n",
    "\n",
    "    if not results:\n",
    "        return {**state, 'explanation': 'No products found for your query.'}\n",
    "\n",
    "    # Build a summary of the results for the LLM\n",
    "    products_summary = '\\n'.join([\n",
    "        f\"{i+1}. {r['title'][:60]} \"\n",
    "        f\"(${r.get('price', 'N/A'):.2f} | {r.get('rating', 'N/A')}â­)\"\n",
    "        for i, r in enumerate(results)\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"You are ShopSense, a helpful shopping assistant.\n",
    "\n",
    "A user searched for: \"{query}\"\n",
    "\n",
    "You recommended these products:\n",
    "{products_summary}\n",
    "\n",
    "Write a brief, friendly explanation (3-4 sentences) of:\n",
    "1. Why these products match what the user is looking for\n",
    "2. What makes the top recommendation stand out\n",
    "3. Any useful shopping tip related to their query\n",
    "\n",
    "Be conversational and helpful. No bullet points â€” just natural sentences.\"\"\"\n",
    "\n",
    "    response = groq_client.chat.completions.create(\n",
    "        model=GROQ_MODEL,\n",
    "        messages=[{'role': 'user', 'content': prompt}],\n",
    "        max_tokens=150,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        'explanation': response.choices[0].message.content.strip()\n",
    "    }\n",
    "\n",
    "\n",
    "print('âœ… Five nodes defined:')\n",
    "print('   1. analyze_node  â€” extract intent + filters')\n",
    "print('   2. clarify_node  â€” ask follow-up if vague')\n",
    "print('   3. search_node   â€” FAISS semantic search')\n",
    "print('   4. filter_node   â€” apply constraints')\n",
    "print('   5. explain_node  â€” generate explanation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 â€” Build the LangGraph\n",
    "\n",
    "Now we wire the nodes together into a graph.\n",
    "The graph defines which node runs after which, and what decisions cause branching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LangGraph agent compiled!\n",
      "\n",
      "Graph flow:\n",
      "  START â†’ analyze â†’ [if vague] â†’ clarify â†’ END\n",
      "                  â†’ [if clear] â†’ search â†’ filter â†’ explain â†’ END\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# â”€â”€ Create the graph with our state type â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "# â”€â”€ Add all nodes to the graph â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "graph.add_node('analyze', analyze_node)\n",
    "graph.add_node('clarify', clarify_node)\n",
    "graph.add_node('search',  search_node)\n",
    "graph.add_node('filter',  filter_node)\n",
    "graph.add_node('explain', explain_node)\n",
    "\n",
    "# â”€â”€ Set the entry point (first node to run) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "graph.set_entry_point('analyze')\n",
    "\n",
    "# â”€â”€ Add conditional edge from analyze â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# This is the branching logic:\n",
    "# After analyze runs, check needs_clarification.\n",
    "# If True  â†’ go to clarify node (ask user a question)\n",
    "# If False â†’ go to search node (search for products)\n",
    "\n",
    "def route_after_analyze(state: AgentState) -> str:\n",
    "    \"\"\"Routing function â€” decides which node to visit after analyze.\"\"\"\n",
    "    if state.get('needs_clarification'):\n",
    "        return 'clarify'\n",
    "    return 'search'\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    'analyze',                              # from this node\n",
    "    route_after_analyze,                    # call this function to decide\n",
    "    {'clarify': 'clarify', 'search': 'search'}  # map return value to node name\n",
    ")\n",
    "\n",
    "# â”€â”€ Add straight edges (no branching) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# clarify â†’ END (we stop and show the question to the user)\n",
    "# search  â†’ filter â†’ explain â†’ END\n",
    "graph.add_edge('clarify', END)\n",
    "graph.add_edge('search',  'filter')\n",
    "graph.add_edge('filter',  'explain')\n",
    "graph.add_edge('explain', END)\n",
    "\n",
    "# â”€â”€ Compile the graph into a runnable agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "agent = graph.compile()\n",
    "\n",
    "print('âœ… LangGraph agent compiled!')\n",
    "print()\n",
    "print('Graph flow:')\n",
    "print('  START â†’ analyze â†’ [if vague] â†’ clarify â†’ END')\n",
    "print('                  â†’ [if clear] â†’ search â†’ filter â†’ explain â†’ END')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 â€” Build the Agent Runner Function\n",
    "A clean wrapper that runs the agent and displays results nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… run_agent() ready.\n"
     ]
    }
   ],
   "source": [
    "def run_agent(query: str, verbose: bool = True) -> dict:\n",
    "    \"\"\"\n",
    "    Run the ShopSense agent for a user query.\n",
    "\n",
    "    Args:\n",
    "        query   : Natural language user query\n",
    "        verbose : If True, prints step-by-step agent reasoning\n",
    "\n",
    "    Returns:\n",
    "        Final agent state dict\n",
    "    \"\"\"\n",
    "    # Initial state â€” everything empty except the query\n",
    "    initial_state: AgentState = {\n",
    "        'query'               : query,\n",
    "        'intent'              : None,\n",
    "        'filters'             : {},\n",
    "        'search_results'      : None,\n",
    "        'final_results'       : None,\n",
    "        'clarify_question'    : None,\n",
    "        'explanation'         : None,\n",
    "        'needs_clarification' : False\n",
    "    }\n",
    "\n",
    "    print(f'\\n{\"=\"*65}')\n",
    "    print(f'ğŸ›ï¸  ShopSense Agent')\n",
    "    print(f'ğŸ“ Query: \"{query}\"')\n",
    "    print(f'{\"=\"*65}')\n",
    "\n",
    "    # Run the graph â€” it handles all the node routing automatically\n",
    "    final_state = agent.invoke(initial_state)\n",
    "\n",
    "    # â”€â”€ Display agent reasoning (verbose mode) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if verbose:\n",
    "        print(f'\\nğŸ§  Agent Reasoning:')\n",
    "        print(f'   Intent  : {final_state.get(\"intent\", \"search\")}')\n",
    "        filters = final_state.get('filters') or {}\n",
    "        active_filters = {k: v for k, v in filters.items() if v is not None}\n",
    "        if active_filters:\n",
    "            print(f'   Filters : {active_filters}')\n",
    "        else:\n",
    "            print(f'   Filters : none')\n",
    "\n",
    "    # â”€â”€ Handle clarification case â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if final_state.get('needs_clarification'):\n",
    "        print(f'\\nâ“ Agent needs clarification:')\n",
    "        print(f'   {final_state[\"clarify_question\"]}')\n",
    "        return final_state\n",
    "\n",
    "    # â”€â”€ Display results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    results = final_state.get('final_results') or []\n",
    "    print(f'\\nğŸ“¦ Top {len(results)} Recommendations:')\n",
    "    print('â”€' * 65)\n",
    "\n",
    "    for i, r in enumerate(results, 1):\n",
    "        price_str = f\"${r['price']:.2f}\" if r.get('price') else 'N/A'\n",
    "        print(f\"{i}. {r['title'][:68]}\")\n",
    "        print(f\"   ğŸ’° {price_str}  |  â­ {r.get('rating', 'N/A')} \"\n",
    "              f\"({int(r.get('rating_count', 0)):,} reviews)\")\n",
    "        print(f\"   Relevance score: {r.get('similarity_score', 'N/A')}\")\n",
    "        print()\n",
    "\n",
    "    # â”€â”€ Display explanation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if final_state.get('explanation'):\n",
    "        print('ğŸ’¬ Agent Explanation:')\n",
    "        print(f\"   {final_state['explanation']}\")\n",
    "\n",
    "    print(f'\\n{\"=\"*65}')\n",
    "    return final_state\n",
    "\n",
    "\n",
    "print('âœ… run_agent() ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 â€” Test the Agent\n",
    "Let's run several queries and watch the agent reason through each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "ğŸ›ï¸  ShopSense Agent\n",
      "ğŸ“ Query: \"compact coffee maker for small kitchen\"\n",
      "=================================================================\n",
      "\n",
      "ğŸ§  Agent Reasoning:\n",
      "   Intent  : search\n",
      "   Filters : none\n",
      "\n",
      "ğŸ“¦ Top 5 Recommendations:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "1. Small Coffee Table White Modern Wood Mini Rectangle Coffee Tables fo\n",
      "   ğŸ’° $52.42  |  â­ 4.6 (80 reviews)\n",
      "   Relevance score: 0.5822\n",
      "\n",
      "2. Famiworths Single Serve Coffee Maker for K Cup and Ground Coffee, 6 \n",
      "   ğŸ’° $22.99  |  â­ 3.9 (246 reviews)\n",
      "   Relevance score: 0.537\n",
      "\n",
      "3. Famiworths Single Serve Coffee Maker for K Cup and Ground Coffee, 6 \n",
      "   ğŸ’° $46.18  |  â­ 4.3 (4,620 reviews)\n",
      "   Relevance score: 0.5354\n",
      "\n",
      "4. Black & Decker DCM7 Cup-at-a-Time Personal 12-Ounce Coffeemaker, Whi\n",
      "   ğŸ’° $22.99  |  â­ 3.6 (237 reviews)\n",
      "   Relevance score: 0.5084\n",
      "\n",
      "5. Home Basics Stainless Steel Stove Top Espresso Coffee Maker (Silver)\n",
      "   ğŸ’° $15.88  |  â­ 3.8 (52 reviews)\n",
      "   Relevance score: 0.4936\n",
      "\n",
      "ğŸ’¬ Agent Explanation:\n",
      "   I think I've found some great options for you in compact coffee makers that are perfect for small kitchens. These products match what you're looking for because they're all designed to be space-saving and easy to use, with features like single-serve brewing and compact designs. \n",
      "\n",
      "The top recommendation, the Small Coffee Table White Modern Wood Mini Rectangle Coffee T, stands out because it's a versatile piece that doubles as a coffee table and a coffee maker, making it perfect for small kitchens where counter space is limited. Not only will it save you space, but it'll also add a touch of modern style to your kitchen.\n",
      "\n",
      "When shopping for a compact coffee maker, keep in mind that you don't always need the most expensive option to get the job done\n",
      "\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 1 â€” clear query, no filters\n",
    "state1 = run_agent('compact coffee maker for small kitchen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "ğŸ›ï¸  ShopSense Agent\n",
      "ğŸ“ Query: \"non stick frying pan under $30\"\n",
      "=================================================================\n",
      "\n",
      "ğŸ§  Agent Reasoning:\n",
      "   Intent  : search\n",
      "   Filters : {'max_price': 30}\n",
      "\n",
      "ğŸ“¦ Top 5 Recommendations:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "1. Anyfish 8 Inch Frying Pan without Lid Nonstick Induction Skillet Sma\n",
      "   ğŸ’° $22.99  |  â­ 4.2 (29 reviews)\n",
      "   Relevance score: 0.6875\n",
      "\n",
      "2. MICHELANGELO Frying Pan with Lid, Nonstick 8 Inch Frying Pan with Ce\n",
      "   ğŸ’° $23.99  |  â­ 4.4 (10,637 reviews)\n",
      "   Relevance score: 0.6424\n",
      "\n",
      "3. NGORAY Pancake Egg Frying Pan Nonstick Mini - 4 Cups Cast Iron Omele\n",
      "   ğŸ’° $22.99  |  â­ 4.1 (19 reviews)\n",
      "   Relevance score: 0.6303\n",
      "\n",
      "4. EOXHOME 8 Inch Non Stick Stone Coating Cookware Nonstick Skillet Fry\n",
      "   ğŸ’° $22.99  |  â­ 4.5 (424 reviews)\n",
      "   Relevance score: 0.6065\n",
      "\n",
      "5. Copper Frying Pan 11-Inch Non Stick Ceramic Infused Titanium Steel O\n",
      "   ğŸ’° $16.99  |  â­ 4.3 (57 reviews)\n",
      "   Relevance score: 0.6061\n",
      "\n",
      "ğŸ’¬ Agent Explanation:\n",
      "   I've got just the thing for you if you're looking for a non-stick frying pan. These five products match your search because they all feature non-stick coatings and are designed for cooking delicious meals with ease.\n",
      "\n",
      "As for what makes our top recommendation stand out, it's the EOXHOME 8 Inch Non Stick Stone Coating Cookware Nonstick Ski, which boasts an impressive 4.5-star rating. This non-stick frying pan features a unique stone coating that's not only durable but also safe for high-heat cooking, making it a top choice for anyone looking for a reliable cooking experience.\n",
      "\n",
      "If you're shopping for a non-stick frying pan, one useful tip to keep in mind is to read reviews carefully and check\n",
      "\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 2 â€” query with price filter (agent should extract max_price=30)\n",
    "state2 = run_agent('non stick frying pan under $30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "ğŸ›ï¸  ShopSense Agent\n",
      "ğŸ“ Query: \"highly rated storage bins for closet\"\n",
      "=================================================================\n",
      "\n",
      "ğŸ§  Agent Reasoning:\n",
      "   Intent  : search\n",
      "   Filters : {'min_rating': 4, 'keyword': 'storage bins'}\n",
      "\n",
      "ğŸ“¦ Top 5 Recommendations:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "1. Plastic Storage Bins with Lids and Wheels - For Toys Shoes Clothes B\n",
      "   ğŸ’° $22.99  |  â­ 4.6 (626 reviews)\n",
      "   Relevance score: 0.6616\n",
      "\n",
      "2. Superio Ribbed Collection - Decorative Plastic Lidded Home Storage B\n",
      "   ğŸ’° $47.97  |  â­ 4.4 (36 reviews)\n",
      "   Relevance score: 0.6502\n",
      "\n",
      "3. Superio Ribbed Collection - Decorative Plastic Open Home Storage Bin\n",
      "   ğŸ’° $29.83  |  â­ 4.4 (84 reviews)\n",
      "   Relevance score: 0.6407\n",
      "\n",
      "4. ANMINY Storage Bins with Zipper Lid Storage Boxes with Handles PP Pl\n",
      "   ğŸ’° $26.99  |  â­ 4.7 (363 reviews)\n",
      "   Relevance score: 0.6119\n",
      "\n",
      "5. Foldable Storage Bins Linen Fabric with Lid and Handle for Home Bedr\n",
      "   ğŸ’° $22.99  |  â­ 4.5 (20 reviews)\n",
      "   Relevance score: 0.6036\n",
      "\n",
      "ğŸ’¬ Agent Explanation:\n",
      "   When searching for highly rated storage bins for your closet, I've curated a list of top picks that cater to your needs. These products match what you're looking for because they offer a mix of functionality, durability, and style â€“ from plastic storage bins with wheels to decorative options that can add a touch of elegance to your closet space.\n",
      "\n",
      "The top recommendation, the Plastic Storage Bins with Lids and Wheels - For Toys Shoes C, stands out because of its excellent balance of price and quality. For just under $23, you get a spacious storage bin with a lid and wheels that can help keep your closet organized and make the most of your space.\n",
      "\n",
      "As you shop for storage bins, consider the size and material that best fit your needs. Since\n",
      "\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 3 â€” query with rating filter\n",
    "state3 = run_agent('highly rated storage bins for closet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "ğŸ›ï¸  ShopSense Agent\n",
      "ğŸ“ Query: \"something nice\"\n",
      "=================================================================\n",
      "\n",
      "ğŸ§  Agent Reasoning:\n",
      "   Intent  : clarify\n",
      "   Filters : none\n",
      "\n",
      "â“ Agent needs clarification:\n",
      "   What is this general product for (e.g. home, office, hobby, or a specific task)?\n"
     ]
    }
   ],
   "source": [
    "# Test 4 â€” vague query (agent should ask for clarification)\n",
    "state4 = run_agent('something nice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "ğŸ›ï¸  ShopSense Agent\n",
      "ğŸ“ Query: \"best knife set under $50 with 4 stars and above\"\n",
      "=================================================================\n",
      "\n",
      "ğŸ§  Agent Reasoning:\n",
      "   Intent  : search\n",
      "   Filters : {'max_price': 50, 'min_rating': 4, 'keyword': 'knife set'}\n",
      "\n",
      "ğŸ“¦ Top 5 Recommendations:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "1. TOP CHEF - Dynasty 9-Piece Block Knife Set - German Stainless Steel \n",
      "   ğŸ’° $22.99  |  â­ 4.6 (17 reviews)\n",
      "   Relevance score: 0.582\n",
      "\n",
      "2. Kitchen Chef Knives Set with Wood Grain Handle 6 Pieces Stainless St\n",
      "   ğŸ’° $22.99  |  â­ 4.4 (537 reviews)\n",
      "   Relevance score: 0.5797\n",
      "\n",
      "3. Daanaas Knife Set with Wooden Block and Sharpener 16 Pieces,Professi\n",
      "   ğŸ’° $49.99  |  â­ 4.4 (54 reviews)\n",
      "   Relevance score: 0.5569\n",
      "\n",
      "4. Professional Chef Knife Set 5 Pieces, Kitchen Knives Set Stainless S\n",
      "   ğŸ’° $22.99  |  â­ 4.3 (64 reviews)\n",
      "   Relevance score: 0.5499\n",
      "\n",
      "5. Cangshan S+ Series 1022094 German Steel Forged 2-Piece Titanium Coat\n",
      "   ğŸ’° $49.95  |  â­ 4.7 (140 reviews)\n",
      "   Relevance score: 0.5435\n",
      "\n",
      "ğŸ’¬ Agent Explanation:\n",
      "   You're looking for a great knife set that won't break the bank, and we've got some fantastic options for you. All of these products match what you're looking for because they're high-quality knife sets that are available for under $50. We've included a range of options with different numbers of pieces, handle styles, and features, so you're sure to find the perfect fit for your kitchen.\n",
      "\n",
      "Our top recommendation, the TOP CHEF - Dynasty 9-Piece Block Knife Set, stands out because it offers an impressive 9-piece set at an incredibly affordable price of just $22.99. The fact that it's made from German stainless steel and has a 4.6-star rating really makes it a standout choice in this\n",
      "\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 5 â€” query with both price and rating filters\n",
    "state5 = run_agent('best knife set under $50 with 4 stars and above')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "ğŸ›ï¸  ShopSense Agent\n",
      "ğŸ“ Query: \"gift for someone who loves cooking under $25\"\n",
      "=================================================================\n",
      "\n",
      "ğŸ§  Agent Reasoning:\n",
      "   Intent  : search\n",
      "   Filters : {'max_price': 25}\n",
      "\n",
      "ğŸ“¦ Top 5 Recommendations:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "1. LITSTYLES Charcuterie Boards, Bamboo Cheese Board & Knife Set, Premi\n",
      "   ğŸ’° $20.99  |  â­ 3.9 (26 reviews)\n",
      "   Relevance score: 0.5198\n",
      "\n",
      "2. Funny Fork Gifts for Women Men Kids, Cute My Mac and Cheese Fork Eng\n",
      "   ğŸ’° $10.99  |  â­ 5.0 (11 reviews)\n",
      "   Relevance score: 0.5071\n",
      "\n",
      "3. Landisun Apron Kitchen Chef Cooking Gag Gift Creative Funny Grilling\n",
      "   ğŸ’° $14.99  |  â­ 4.6 (154 reviews)\n",
      "   Relevance score: 0.5005\n",
      "\n",
      "4. Funny Gifts for Women Wife Girlfriend Friends, 20 oz Wine Tumbler wi\n",
      "   ğŸ’° $22.99  |  â­ 4.6 (59 reviews)\n",
      "   Relevance score: 0.4919\n",
      "\n",
      "5. Not a Day Over Fabulous Wine Tumbler, Fun Birthday Gifts for Women W\n",
      "   ğŸ’° $22.99  |  â­ 4.6 (354 reviews)\n",
      "   Relevance score: 0.4717\n",
      "\n",
      "ğŸ’¬ Agent Explanation:\n",
      "   If you're looking for the perfect gift for someone who loves cooking, we've got some fantastic suggestions for you. These products match what you're looking for because they're all related to cooking, entertaining, or wine - things that a cooking enthusiast is likely to enjoy. \n",
      "\n",
      "Our top recommendation is the LITSTYLES Charcuterie Boards, Bamboo Cheese Board & Knife Set, which stands out because it's a practical and versatile gift that can be used for a variety of occasions, from casual dinner parties to special events. I think this one is a great choice because it's made of high-quality bamboo, which is both durable and eco-friendly.\n",
      "\n",
      "When shopping for a gift for a cooking enthusiast, keep in mind that it's the thought and personal\n",
      "\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 6 â€” try your own query!\n",
    "state6 = run_agent('gift for someone who loves cooking under $25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 â€” Inspect Agent State\n",
    "Shows exactly what the agent stored at each step â€” useful for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full agent state for \"non stick frying pan under $30\":\n",
      "  Query (refined) : non stick frying pan\n",
      "  Intent          : search\n",
      "  Filters         : {'max_price': 30, 'min_price': None, 'min_rating': None, 'keyword': None}\n",
      "  Results count   : 5\n",
      "  Explanation     : I've got just the thing for you if you're looking for a non-stick frying pan. These five products ma...\n"
     ]
    }
   ],
   "source": [
    "# Inspect the full state from Test 2 (price filter query)\n",
    "print('Full agent state for \"non stick frying pan under $30\":')\n",
    "print(f'  Query (refined) : {state2[\"query\"]}')\n",
    "print(f'  Intent          : {state2[\"intent\"]}')\n",
    "print(f'  Filters         : {state2[\"filters\"]}')\n",
    "print(f'  Results count   : {len(state2.get(\"final_results\") or [])}')\n",
    "print(f'  Explanation     : {state2.get(\"explanation\", \"\")[:100]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9 â€” Save Agent as Reusable Module\n",
    "Saves `agent.py` so Phase 9 (FastAPI) can import it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… agent.py saved â€” ready for Phase 9 FastAPI import\n"
     ]
    }
   ],
   "source": [
    "agent_module = '''\n",
    "\"\"\"\n",
    "ShopSense Agent Module\n",
    "Reusable agent for Phase 9 FastAPI backend.\n",
    "Usage:\n",
    "    from agent import run_shopsense_agent\n",
    "    result = run_shopsense_agent(\"compact coffee maker\")\n",
    "\"\"\"\n",
    "\n",
    "import os, json, re, faiss, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Optional\n",
    "\n",
    "load_dotenv()\n",
    "DATA_DIR   = Path(\"data\")\n",
    "GROQ_MODEL = \"llama-3.1-8b-instant\"\n",
    "\n",
    "# Load all components\n",
    "embed_model      = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "product_index    = faiss.read_index(str(DATA_DIR / \"faiss_index.bin\"))\n",
    "review_index     = faiss.read_index(str(DATA_DIR / \"reviews_faiss_index.bin\"))\n",
    "groq_client      = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "with open(DATA_DIR / \"faiss_metadata.json\") as f:\n",
    "    product_metadata = json.load(f)\n",
    "with open(DATA_DIR / \"reviews_metadata.json\") as f:\n",
    "    review_chunks = json.load(f)\n",
    "\n",
    "df_products  = pd.read_csv(DATA_DIR / \"products_clean.csv\")\n",
    "median_price = df_products[\"price\"].median()\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    intent: Optional[str]\n",
    "    filters: Optional[dict]\n",
    "    search_results: Optional[list]\n",
    "    final_results: Optional[list]\n",
    "    clarify_question: Optional[str]\n",
    "    explanation: Optional[str]\n",
    "    needs_clarification: bool\n",
    "\n",
    "\n",
    "def search_tool(query, top_k=20):\n",
    "    q = embed_model.encode([query], normalize_embeddings=True, convert_to_numpy=True).astype(\"float32\")\n",
    "    scores, indices = product_index.search(q, top_k)\n",
    "    results = []\n",
    "    for score, idx in zip(scores[0], indices[0]):\n",
    "        if idx == -1: continue\n",
    "        p = product_metadata[idx].copy()\n",
    "        p[\"similarity_score\"] = round(float(score), 4)\n",
    "        if not p.get(\"price\") or str(p.get(\"price\")) == \"nan\": p[\"price\"] = median_price\n",
    "        results.append(p)\n",
    "    return results\n",
    "\n",
    "\n",
    "def filter_tool(products, max_price=None, min_price=None, min_rating=None, keyword=None):\n",
    "    f = products\n",
    "    if max_price: f = [p for p in f if p.get(\"price\", 0) <= max_price]\n",
    "    if min_price: f = [p for p in f if p.get(\"price\", 0) >= min_price]\n",
    "    if min_rating: f = [p for p in f if p.get(\"rating\", 0) >= min_rating]\n",
    "    if keyword:\n",
    "        kw = keyword.lower()\n",
    "        f = [p for p in f if kw in p.get(\"title\",\"\").lower() or kw in p.get(\"description\",\"\").lower()]\n",
    "    return f if len(f) >= 3 else products[:10]\n",
    "\n",
    "\n",
    "def analyze_node(state):\n",
    "    query = state[\"query\"]\n",
    "    prompt = f\"\"\"Analyze this shopping query: \"{query}\"\n",
    "Respond with JSON: {{\"intent\": \"search\" or \"clarify\", \"needs_clarification\": bool,\n",
    "\"search_query\": \"improved query\", \"filters\": {{\"max_price\": null or number,\n",
    "\"min_price\": null or number, \"min_rating\": null or number, \"keyword\": null or string}}}}\n",
    "Only clarify if extremely vague. JSON only.\"\"\"\n",
    "    r = groq_client.chat.completions.create(model=GROQ_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}], max_tokens=200, temperature=0.1)\n",
    "    try:\n",
    "        p = json.loads(re.sub(r\"```json|```\", \"\", r.choices[0].message.content).strip())\n",
    "        fi = p.get(\"filters\", {})\n",
    "        return {**state, \"intent\": p.get(\"intent\", \"search\"),\n",
    "                \"needs_clarification\": p.get(\"needs_clarification\", False),\n",
    "                \"query\": p.get(\"search_query\", query),\n",
    "                \"filters\": {\"max_price\": fi.get(\"max_price\"), \"min_price\": fi.get(\"min_price\"),\n",
    "                             \"min_rating\": fi.get(\"min_rating\"), \"keyword\": fi.get(\"keyword\")}}\n",
    "    except: return {**state, \"intent\": \"search\", \"needs_clarification\": False, \"filters\": {}}\n",
    "\n",
    "\n",
    "def clarify_node(state):\n",
    "    r = groq_client.chat.completions.create(model=GROQ_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": f'Query: \"{state[\"query\"]}\" is vague. Ask ONE clarifying question under 20 words.'}],\n",
    "        max_tokens=50, temperature=0.5)\n",
    "    return {**state, \"clarify_question\": r.choices[0].message.content.strip()}\n",
    "\n",
    "\n",
    "def search_node(state):\n",
    "    return {**state, \"search_results\": search_tool(state[\"query\"])}\n",
    "\n",
    "\n",
    "def filter_node(state):\n",
    "    fi = state.get(\"filters\") or {}\n",
    "    filtered = filter_tool(state.get(\"search_results\") or [],\n",
    "        max_price=fi.get(\"max_price\"), min_price=fi.get(\"min_price\"),\n",
    "        min_rating=fi.get(\"min_rating\"), keyword=fi.get(\"keyword\"))\n",
    "    return {**state, \"final_results\": filtered[:5]}\n",
    "\n",
    "\n",
    "def explain_node(state):\n",
    "    results = state.get(\"final_results\") or []\n",
    "    if not results: return {**state, \"explanation\": \"No products found.\"}\n",
    "    summary = \"\\n\".join([f\"{i+1}. {r[\\'title\\'][:60]} (${r.get(\\'price\\',0):.2f} | {r.get(\\'rating\\')}â­)\"\n",
    "                          for i, r in enumerate(results)])\n",
    "    r = groq_client.chat.completions.create(model=GROQ_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"User searched: \\\"{state[\\'query\\']}\\\"\\nRecommended:\\n{summary}\\nWrite 3-4 friendly sentences explaining why these match.\"}],\n",
    "        max_tokens=150, temperature=0.7)\n",
    "    return {**state, \"explanation\": r.choices[0].message.content.strip()}\n",
    "\n",
    "\n",
    "# Build graph\n",
    "_graph = StateGraph(AgentState)\n",
    "_graph.add_node(\"analyze\", analyze_node)\n",
    "_graph.add_node(\"clarify\", clarify_node)\n",
    "_graph.add_node(\"search\",  search_node)\n",
    "_graph.add_node(\"filter\",  filter_node)\n",
    "_graph.add_node(\"explain\", explain_node)\n",
    "_graph.set_entry_point(\"analyze\")\n",
    "_graph.add_conditional_edges(\"analyze\",\n",
    "    lambda s: \"clarify\" if s.get(\"needs_clarification\") else \"search\",\n",
    "    {\"clarify\": \"clarify\", \"search\": \"search\"})\n",
    "_graph.add_edge(\"clarify\", END)\n",
    "_graph.add_edge(\"search\",  \"filter\")\n",
    "_graph.add_edge(\"filter\",  \"explain\")\n",
    "_graph.add_edge(\"explain\", END)\n",
    "_agent = _graph.compile()\n",
    "\n",
    "\n",
    "def run_shopsense_agent(query: str) -> dict:\n",
    "    \"\"\"Main entry point for the ShopSense agent. Used by FastAPI in Phase 9.\"\"\"\n",
    "    state = _agent.invoke({\n",
    "        \"query\": query, \"intent\": None, \"filters\": {},\n",
    "        \"search_results\": None, \"final_results\": None,\n",
    "        \"clarify_question\": None, \"explanation\": None,\n",
    "        \"needs_clarification\": False\n",
    "    })\n",
    "    return {\n",
    "        \"query\"              : state[\"query\"],\n",
    "        \"needs_clarification\": state.get(\"needs_clarification\", False),\n",
    "        \"clarify_question\"   : state.get(\"clarify_question\"),\n",
    "        \"results\"            : state.get(\"final_results\") or [],\n",
    "        \"explanation\"        : state.get(\"explanation\"),\n",
    "        \"filters_applied\"    : state.get(\"filters\") or {}\n",
    "    }\n",
    "'''\n",
    "\n",
    "with open('agent.py', 'w') as f:\n",
    "    f.write(agent_module)\n",
    "\n",
    "print('âœ… agent.py saved â€” ready for Phase 9 FastAPI import')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
